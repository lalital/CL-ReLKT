{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Use CL-ReKLT model to perform online prompt mining and evaluate the results\n",
    "\n",
    "---\n",
    "\n",
    "Created on: 4 May, 11:35\n",
    "\n",
    "Task: Experiment: Use CL-ReKLT model to perform online prompt mining and evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import os, sys\n",
    "import json\n",
    "import jsonlines\n",
    "import glob\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# sentence tokenizer\n",
    "from typing import List, Dict, Tuple\n",
    "from pythainlp.tokenize import word_tokenize as th_word_tokenize\n",
    "from nltk.tokenize import word_tokenize as en_word_tokenize, sent_tokenize as en_sent_tokenize\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Given a question $q_i$ from the train/val or test set of a QA dataset, select the groundtruth passage $p_i$.\n",
    "\n",
    "2. Then, perform sentence tokenization with     `nltk.tokenize.sent_tokenize` on the paired passage to obtain a list of sentences $s^i_j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$.\n",
    "\n",
    "3. Find the top-k candidates determined by the cosine similarity scores of question and sentences $\\textrm{similarity\\_score} = \\textrm{embed}(q_i) \\cdot \\textrm{embed}(s^i_j)$. \n",
    "\n",
    "4. Test the ranked candidates against the ground-truth sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_sentence(text:str) -> List[str]:\n",
    "    return en_sent_tokenize(text)\n",
    "\n",
    "def find_sentences_matched_answer(answer: str, sentences: List[str]) -> List[Tuple[str, Tuple[int, int]]]:\n",
    "    sentence_candidates = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if answer in sentence:\n",
    "            search_obj = re.search(answer, sentence)\n",
    "            sentence_candidates.append((sentence, answer, search_obj.span(0)))\n",
    "\n",
    "    return sentence_candidates\n",
    "\n",
    "def find_gt_sentence(qa_item, document):\n",
    "    \n",
    "    segments = segment_sentence(document)\n",
    "    pass\n",
    "\n",
    "def compute_dot_product_sim(query, keys):\n",
    "    scores = np.inner(query, keys)\n",
    "    return scores\n",
    "import heapq\n",
    "def select_candidate(question, sentence_candidates, method='first', model=None, topk=10):\n",
    "    if method == 'first':\n",
    "        return sentence_candidates[0]\n",
    "    elif method == 'vsim_dot':\n",
    "        q_vector = model(question)\n",
    "        s_vectors = model(sentence_candidates)\n",
    "        scores = compute_dot_product_sim(q_vector, s_vectors)\n",
    "\n",
    "        K = min(topk, len(sentence_candidates))\n",
    "#         print(scores)\n",
    "        topk_indices = heapq.nlargest(K, range(len(sentence_candidates)), scores.take)\n",
    "\n",
    "\n",
    "#         print(topk_indices)\n",
    "        return [(sentence_candidates[i], float(scores[0][i])) for i in topk_indices]\n",
    "    else:\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'What year did Tesla die?'\n",
    "v =['Tesla died on 7 January 1943.', 'There has been a resurgence in popular interest in Tesla since the 1990s', 'His work fell into relative obscurity after his death.']\n",
    "# select_candidate(q,v,method='vsim_dot', model=xquad_student_supported_langs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p{width: 700px; color: #333; padding: 5px 30px}\n",
      "span.answer{\n",
      " background-color: #488FB150;\n",
      " color: #333;\n",
      " border-right: 4px solid #488FB1;\n",
      " align-items: center;\n",
      "  margin: 0;\n",
      " padding: 2px 8px;\n",
      " border-radius: 3px;}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "color_mapper = {\n",
    " \"answer\": \"#488FB1\",\n",
    "}\n",
    "css_text = 'p{width: 700px; color: #333; padding: 5px 30px}\\n'\n",
    "\n",
    "for k,v in color_mapper.items():\n",
    "    css_text += \"span.\"+f\"{k.lower()}\" \\\n",
    "    +\"{\\n background-color: \" \\\n",
    "    +f\"{v}\"+\"50;\\n color: #333;\\n border-right: 4px solid \" \\\n",
    "    +f\"{v}\"+\";\" \\\n",
    "    + \"\\n align-items: center;\" \\\n",
    "    + \"\\n  margin: 0;\" \\\n",
    "    + \"\\n padding: 2px 8px;\" \\\n",
    "    + \"\\n border-radius: 3px;}\"\n",
    "    \n",
    "HTML(f\"\"\"\n",
    "<style>\n",
    "{css_text}\n",
    "</style>\n",
    "\"\"\")\n",
    "\n",
    "print(css_text)\n",
    "def render_doc(doc: str):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f\"\"\"\n",
    "    <style>\n",
    "    {css_text}\n",
    "    </style>\n",
    "    \"\"\"))\n",
    "    display(HTML(f'<p>{doc}</p>'))\n",
    "def visualize(question, candidate_item, paragraph):\n",
    "#     print(f'Question: {question}')\n",
    "    sentence_candidate = candidate_item[0]\n",
    "    answer_span = candidate_item[1]\n",
    "#     print(f'Answer: {answer_span}')\n",
    "#     print(f'Sentence containing answer: {sentence_candidate}')\n",
    "\n",
    "    search_obj = re.search(sentence_candidate, paragraph)\n",
    "    assert search_obj != None\n",
    "    start,end = search_obj.span(0)\n",
    "    \n",
    "    paragraph_with_label_tag = paragraph[:start] + '<span class=\"answer\">' + paragraph[start:end] + \\\n",
    "                            '</span>' + paragraph[end:] \n",
    "#     print('\\nContext:\\n')\n",
    "    render_doc(paragraph_with_label_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) xQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['data', 'version']), '1.1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XQUAD_BASE_DIR = '../data/xquad/xx/'\n",
    "xquad_en = json.load(open(os.path.join(XQUAD_BASE_DIR, 'xquad.en.json'), 'r'))\n",
    "xquad_en.keys(), \\\n",
    "xquad_en['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xquad_answer_str(context, qas):\n",
    "    context_qa_pairs = []\n",
    "    for qa in qas:\n",
    "        question = qa['question']\n",
    "        answer = qa['answers'][0]['text']\n",
    "        answer_start = qa['answers'][0]['answer_start']\n",
    "        context_qa_pairs.append((context, question, answer, answer_start))\n",
    "    return context_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tesla was renowned for his achievements and showmanship, eventually earning him a reputation in popular culture as an archetypal \"mad scientist\". His patents earned him a considerable amount of money, much of which was used to finance his own projects with varying degrees of success.:121,154 He lived most of his life in a series of New York hotels, through his retirement. Tesla died on 7 January 1943. His work fell into relative obscurity after his death, but in 1960 the General Conference on Weights and Measures named the SI unit of magnetic flux density the tesla in his honor. There has been a resurgence in popular interest in Tesla since the 1990s.',\n",
       " 'What year did Tesla die? ',\n",
       " '1943',\n",
       " 399)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = xquad_en['data'][3]['paragraphs'][0]\n",
    "context_qa_pairs = get_xquad_answer_str(context=item['context'], qas=item['qas'])\n",
    "context_qa_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_prompt_gt(args):\n",
    "    context, question, answer, answer_start = args\n",
    "    sentences = segment_sentence(context)\n",
    "    \n",
    "\n",
    "    acc_len = 0\n",
    "    selected_sentence = '<NA>'\n",
    "#     print(f'answer_start: {answer_start}')\n",
    "    for i, sentence_candidate in enumerate(sentences):\n",
    "        if answer_start >= acc_len and answer_start <=acc_len + len(sentence_candidate):\n",
    "            selected_sentence = sentence_candidate\n",
    "            \n",
    "        acc_len+=len(sentence_candidate)\n",
    "#     print(f'selected_sentence: {selected_sentence}')\n",
    "    prompt_template = 'Question: {} Answer: {}'\n",
    "    \n",
    "#     display(HTML(f'<p>Question: {question}</p>'))\n",
    "#     display(HTML(f'<p>Answer: {answer}</p>'))\n",
    "#     visualize(question=question, candidate_item=(selected_sentence, answer), paragraph=context)\n",
    "    \n",
    "    prompt = prompt_template.format(question.strip(), selected_sentence)\n",
    "#     print('\\nPrompt:\\n')\n",
    "#     print(prompt)\n",
    "#     print('-'*40)\n",
    "    return selected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla died on 7 January 1943.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine_prompt_gt(context_qa_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(directory: str):\n",
    "    \n",
    "    model = hub.load(directory)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 11:13:12.706641: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-11 11:13:12.732829: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe3f583cde0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-05-11 11:13:12.732847: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "muse_small_v3_model = load_model('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "XQUAD_TEACHER_DIR = '../../../CL-ReLKT_store/models/XQUAD/teacher_model/'\n",
    "# XORQA_TEACHER_DIR = '../../../CL-ReLKT_store/models/XORQA/'\n",
    "MLQA_TEACHER_DIR = '../../../CL-ReLKT_store/models/MLQA/teacher_model/'\n",
    "\n",
    "\n",
    "xquad_teacher_model = load_model(XQUAD_TEACHER_DIR)\n",
    "# xorqa_teacher_model = load_model(XORQA_TEACHER_DIR)\n",
    "mlqa_teacher_model = load_model(MLQA_TEACHER_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XQUAD_STUDENT_SUPPORTED_LANGS_DIR = '../../../CL-ReLKT_store/models/XQUAD/student_best_supported_languages/'\n",
    "XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../CL-ReLKT_store/models/XQUAD/student_best_unsupported_languages/'\n",
    "\n",
    "XORQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../CL-ReLKT_store/models/XORQA/student_best_supported_languages/'\n",
    "XORQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../CL-ReLKT_store/models/XORQA/student_best_unsupported_languages/'\n",
    "\n",
    "MLQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../CL-ReLKT_store/models/MLQA/student_best_supported_languages/'\n",
    "MLQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../CL-ReLKT_store/models/MLQA/student_best_unsupported_languages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3bc86bdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3bc86bdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3b12e1830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3b12e1830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe38044d200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe38044d200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "xquad_student_supported_langs_model = load_model(XQUAD_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "xorqa_student_supported_langs_model = load_model(XORQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "mlqa_student_supported_langs_model = load_model(MLQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "\n",
    "\n",
    "xquad_student_unsupported_langs_model = load_model(XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "xorqa_student_unsupported_langs_model = load_model(XORQA_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "mlqa_student_unsupported_langs_model = load_model(MLQA_STUDENT_UNSUPPORTED_LANGS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAPPING = {\n",
    "  'model-xquad_student_supported_langs': xquad_student_supported_langs_model,\n",
    "  'model-xorqa_student_supported_langs': xorqa_student_supported_langs_model,\n",
    "  'model-mlqa_student_supported_langs': mlqa_student_supported_langs_model,\n",
    "  'model-xquad_student_unsupported_langs': xquad_student_unsupported_langs_model,\n",
    "  'model-xorqa_student_unsupported_langs': xorqa_student_unsupported_langs_model,\n",
    "  'model-mlqa_student_unsupported_langs': mlqa_student_unsupported_langs_model,\n",
    "  'model-muse_small_v3_model': muse_small_v3_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3ef76c0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3ef76c0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Tesla died on 7 January 1943.', 0.9757782220840454),\n",
       " ('There has been a resurgence in popular interest in Tesla since the 1990s',\n",
       "  0.9665409922599792),\n",
       " ('His work fell into relative obscurity after his death.', 0.417930543422699)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = 'What year did Tesla die?'\n",
    "v =['Tesla died on 7 January 1943.', 'There has been a resurgence in popular interest in Tesla since the 1990s', 'His work fell into relative obscurity after his death.']\n",
    "select_candidate(q,v,method='vsim_dot', model=xquad_student_supported_langs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3ea7adef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3ea7adef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Tesla died on 7 January 1943.', 0.8128372430801392),\n",
       " ('There has been a resurgence in popular interest in Tesla since the 1990s',\n",
       "  0.7203159928321838),\n",
       " ('His work fell into relative obscurity after his death.',\n",
       "  0.2122974544763565)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_candidate(q,v,method='vsim_dot', model=xorqa_student_supported_langs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3ba5045f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fe3ba5045f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Tesla died on 7 January 1943.', 0.6891652941703796),\n",
       " ('There has been a resurgence in popular interest in Tesla since the 1990s',\n",
       "  0.6083117723464966),\n",
       " ('His work fell into relative obscurity after his death.',\n",
       "  0.25080782175064087)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_candidate(q,v,method='vsim_dot', model=mlqa_student_supported_langs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "class xquad_dataset_item:\n",
    "    question: str\n",
    "    context: str\n",
    "    segmented_context: str\n",
    "    answer: str\n",
    "    answer_start: int\n",
    "    gt_sentence: str\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................"
     ]
    }
   ],
   "source": [
    "xquad_question_counter = Counter()\n",
    "n_paragraph = len(xquad_en['data'])\n",
    "xquad_dataset=[]\n",
    "for i, item in enumerate(xquad_en['data']):\n",
    "    paragraphs = item['paragraphs']\n",
    "    print('.' ,end='')\n",
    "    for j, paragraph in enumerate(paragraphs):\n",
    "        xquad_question_counter[f'd-{i}_p-{j}'] = len(paragraph['qas'])\n",
    "        \n",
    "        context = paragraph['context']\n",
    "        context_qa_pairs = get_xquad_answer_str(context=context, qas=paragraph['qas'])\n",
    "\n",
    "        for context_qa_pair in context_qa_pairs:\n",
    "            context, question, answer, answer_start = context_qa_pair\n",
    "            gt_sentence = mine_prompt_gt(context_qa_pair)\n",
    "            qa_item = {\n",
    "                 'question': question,\n",
    "                    'context': context,\n",
    "                    'segmented_context': segment_sentence(context),\n",
    "                    'answer': answer,\n",
    "                    'answer_start': answer_start,\n",
    "                    'gt_sentence': gt_sentence,\n",
    "            }\n",
    "            xquad_dataset.append(qa_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sum(xquad_question_counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How many points did the Panthers defense surrender?',\n",
       " 'context': \"The Panthers defense gave up just 308 points, ranking sixth in the league, while also leading the NFL in interceptions with 24 and boasting four Pro Bowl selections. Pro Bowl defensive tackle Kawann Short led the team in sacks with 11, while also forcing three fumbles and recovering two. Fellow lineman Mario Addison added 6½ sacks. The Panthers line also featured veteran defensive end Jared Allen, a 5-time pro bowler who was the NFL's active career sack leader with 136, along with defensive end Kony Ealy, who had 5 sacks in just 9 starts. Behind them, two of the Panthers three starting linebackers were also selected to play in the Pro Bowl: Thomas Davis and Luke Kuechly. Davis compiled 5½ sacks, four forced fumbles, and four interceptions, while Kuechly led the team in tackles (118) forced two fumbles, and intercepted four passes of his own. Carolina's secondary featured Pro Bowl safety Kurt Coleman, who led the team with a career high seven interceptions, while also racking up 88 tackles and Pro Bowl cornerback Josh Norman, who developed into a shutdown corner during the season and had four interceptions, two of which were returned for touchdowns.\",\n",
       " 'segmented_context': ['The Panthers defense gave up just 308 points, ranking sixth in the league, while also leading the NFL in interceptions with 24 and boasting four Pro Bowl selections.',\n",
       "  'Pro Bowl defensive tackle Kawann Short led the team in sacks with 11, while also forcing three fumbles and recovering two.',\n",
       "  'Fellow lineman Mario Addison added 6½ sacks.',\n",
       "  \"The Panthers line also featured veteran defensive end Jared Allen, a 5-time pro bowler who was the NFL's active career sack leader with 136, along with defensive end Kony Ealy, who had 5 sacks in just 9 starts.\",\n",
       "  'Behind them, two of the Panthers three starting linebackers were also selected to play in the Pro Bowl: Thomas Davis and Luke Kuechly.',\n",
       "  'Davis compiled 5½ sacks, four forced fumbles, and four interceptions, while Kuechly led the team in tackles (118) forced two fumbles, and intercepted four passes of his own.',\n",
       "  \"Carolina's secondary featured Pro Bowl safety Kurt Coleman, who led the team with a career high seven interceptions, while also racking up 88 tackles and Pro Bowl cornerback Josh Norman, who developed into a shutdown corner during the season and had four interceptions, two of which were returned for touchdowns.\"],\n",
       " 'answer': '308',\n",
       " 'answer_start': 34,\n",
       " 'gt_sentence': 'The Panthers defense gave up just 308 points, ranking sixth in the league, while also leading the NFL in interceptions with 24 and boasting four Pro Bowl selections.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xquad_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataset, key_name, topk=10):\n",
    "    matches_at1 = 0\n",
    "    accuracy = None\n",
    "    matches_at_k = Counter()\n",
    "    for item in dataset:\n",
    "        if item[key_name][0][0] == item['gt_sentence']:\n",
    "            matches_at1+=1\n",
    "        for k in range(min(topk, len(item[key_name]))):\n",
    "            if item[key_name][k][0] == item['gt_sentence']:\n",
    "                matches_at_k[k+1] +=1\n",
    "                break\n",
    "    # key starts from 1 to 10\n",
    "    for k in range(2, topk+1):      \n",
    "       \n",
    "        matches_at_k[k] += matches_at_k[k-1]\n",
    "    precision_at_k = {}\n",
    "    for k, count in matches_at_k.items():        \n",
    "        precision_at_k[k] = float(count / len(dataset))\n",
    "        \n",
    "    accuracy = float(matches_at1 / len(dataset))\n",
    "\n",
    "    return accuracy, precision_at_k\n",
    "\n",
    "def run_online_prompt_mining(dataset, prefix, model):\n",
    "    result_dataset = copy.deepcopy(dataset)\n",
    "#     print(f'prefix: {prefix}')\n",
    "    for item in tqdm(result_dataset, total=len(result_dataset)):\n",
    "        question = item['question']\n",
    "        segmented_context = item['segmented_context']\n",
    "        selected_candidate = select_candidate(question=question, sentence_candidates=segmented_context,\n",
    "                         method='vsim_dot', model=model)\n",
    "        item[f'{prefix}@top_sentence'] = selected_candidate\n",
    "    print('\\n\\tEvaluation result:')\n",
    "        \n",
    "    key_name = f'{prefix}@top_sentence'\n",
    "    accuracy, precision_at_k = evaluate(result_dataset, key_name)\n",
    "    print(f'\\t - Accuracy: {accuracy:.4f}')\n",
    "    print(f'\\t - precision_at_k:')\n",
    "    pprint(precision_at_k)\n",
    "    evaluation_result = (accuracy, precision_at_k)\n",
    "    return evaluation_result, result_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix: dataset-xquad-en_model-xquad_student_sup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1190/1190 [00:19<00:00, 60.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation result:\n",
      " - Accuracy: 0.4681\n",
      " - precision_at_k:\n",
      "{1: 0.4680672268907563,\n",
      " 2: 0.6680672268907563,\n",
      " 3: 0.8050420168067227,\n",
      " 4: 0.8991596638655462,\n",
      " 5: 0.9453781512605042,\n",
      " 6: 0.9815126050420168,\n",
      " 7: 0.9899159663865547,\n",
      " 8: 0.9915966386554622,\n",
      " 9: 0.9957983193277311,\n",
      " 10: 0.9983193277310924}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_xquad_dataset_xquad_student_sup = run_online_prompt_mining(xquad_dataset,\n",
    "                         prefix='dataset-xquad-en_model-xquad_student_sup',\n",
    "                         model=xquad_student_supported_langs_model)\n",
    "\n",
    "# result_xquad_dataset_xquad_student_unsup = run_online_prompt_mining(xquad_dataset,\n",
    "#                          prefix='dataset-xquad-en_model-xquad_student_unsup',\n",
    "#                          model=xquad_student_unsupported_langs_model)\n",
    "# result_xquad_dataset_mlqa_student_sup = run_online_prompt_mining(xquad_dataset,\n",
    "#                          prefix='dataset-xquad-en_model-mlqa_student_sup',\n",
    "#                          model=mlqa_student_supported_langs_model)\n",
    "\n",
    "# result_xquad_dataset_mlqa_student_unsup = run_online_prompt_mining(xquad_dataset,\n",
    "#                          prefix='dataset-xquad-en_model-mlqa_student_unsup',\n",
    "#                          model=mlqa_student_unsupported_langs_model)\n",
    "# result_xquad_dataset_xorqa_student_sup = run_online_prompt_mining(xquad_dataset,\n",
    "#                          prefix='dataset-xquad-en_model-xorqa_student_sup',\n",
    "#                          model=xorqa_student_supported_langs_model)\n",
    "# result_xquad_dataset_xorqa_student_unsup = run_online_prompt_mining(xquad_dataset,\n",
    "#                          prefix='dataset-xquad-en_model-xorqa_student_unsup',\n",
    "#                          model=xorqa_student_unsupported_langs_model)\n",
    "# result_xquad_dataset_xquad_student_sup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) MLQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLQA_BASE_DIR = '../data/mlqa/MLQA_V1/'\n",
    "\n",
    "mlqa_xx = {}\n",
    "MLQA_LANGS = ['en', 'ar', 'de', 'es', 'hi', 'vi', 'zh']\n",
    "for lang in MLQA_LANGS:\n",
    "    mlqa_xx[f'{lang}_val'] = json.load(open(os.path.join(MLQA_BASE_DIR, 'dev', f'dev-context-en-question-{lang}.json'), 'r'))['data'],\n",
    "    mlqa_xx[f'{lang}_test'] = json.load(open(os.path.join(MLQA_BASE_DIR, 'test', f'test-context-en-question-{lang}.json'), 'r'))['data'],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlqa_xx['ar_test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlqa_xx_dataset = defaultdict(lambda: {'val':[], 'test': []})\n",
    "for lang in MLQA_LANGS:\n",
    "\n",
    "    for split_name in ['val', 'test']:\n",
    "        for i, item in enumerate(mlqa_xx[f'{lang}_{split_name}'][0]):\n",
    "#             print(item)\n",
    "#             break\n",
    "            paragraphs = item['paragraphs']\n",
    "    #         print('.' ,end='')\n",
    "            for j, paragraph in enumerate(paragraphs):\n",
    "\n",
    "                context = paragraph['context']\n",
    "                context_qa_pairs = get_xquad_answer_str(context=context, qas=paragraph['qas'])\n",
    "\n",
    "                for context_qa_pair in context_qa_pairs:\n",
    "                    context, question, answer, answer_start = context_qa_pair\n",
    "                    gt_sentence = mine_prompt_gt(context_qa_pair)\n",
    "                    qa_item = {\n",
    "                         'question': question,\n",
    "                            'context': context,\n",
    "                            'segmented_context': segment_sentence(context),\n",
    "                            'answer': answer,\n",
    "                            'answer_start': answer_start,\n",
    "                            'gt_sentence': gt_sentence,\n",
    "                    }\n",
    "                    mlqa_xx_dataset[lang][split_name].append(qa_item)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 5335)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlqa_xx_dataset['ar']['val']), \\\n",
    "len(mlqa_xx_dataset['ar']['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who analyzed the biopsies?',\n",
       " 'context': 'In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency. Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom. Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat. The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza. The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials). They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors. Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told 60 Minutes reporter Lesley Stahl, \"The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit.\"',\n",
       " 'segmented_context': ['In 1994, five unnamed civilian contractors and the widows of contractors Walter Kasza and Robert Frost sued the USAF and the United States Environmental Protection Agency.',\n",
       "  'Their suit, in which they were represented by George Washington University law professor Jonathan Turley, alleged they had been present when large quantities of unknown chemicals had been burned in open pits and trenches at Groom.',\n",
       "  'Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat.',\n",
       "  'The complainants alleged they had sustained skin, liver, and respiratory injuries due to their work at Groom, and that this had contributed to the deaths of Frost and Kasza.',\n",
       "  'The suit sought compensation for the injuries they had sustained, claiming the USAF had illegally handled toxic materials, and that the EPA had failed in its duty to enforce the Resource Conservation and Recovery Act (which governs handling of dangerous materials).',\n",
       "  'They also sought detailed information about the chemicals to which they were allegedly exposed, hoping this would facilitate the medical treatment of survivors.',\n",
       "  'Congressman Lee H. Hamilton, former chairman of the House Intelligence Committee, told 60 Minutes reporter Lesley Stahl, \"The Air Force is classifying all information about Area 51 in order to protect themselves from a lawsuit.\"'],\n",
       " 'answer': 'Rutgers University biochemists',\n",
       " 'answer_start': 457,\n",
       " 'gt_sentence': 'Biopsies taken from the complainants were analyzed by Rutgers University biochemists, who found high levels of dioxin, dibenzofuran, and trichloroethylene in their body fat.'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlqa_xx_dataset['en']['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_mlqa_dataset_xquad_student_sup = run_online_prompt_mining(mlqa_dataset['test'],\n",
    "#                          prefix='dataset-mlqa-en_model-xquad_student_sup',\n",
    "#                          model=xquad_student_supported_langs_model)\n",
    "# result_mlqa_dataset_xquad_student_unsup = run_online_prompt_mining(mlqa_dataset['test'],\n",
    "#                          prefix='dataset-mlqa-en_model-xquad_student_unsup',\n",
    "                                                                   \n",
    "#                          model=xquad_student_unsupported_langs_model)\n",
    "# result_mlqa_dataset_mlqa_student_sup = run_online_prompt_mining(mlqa_dataset['test'],\n",
    "#                          prefix='dataset-mlqa-en_model-mlqa_student_sup',\n",
    "#                          model=mlqa_student_supported_langs_model)\n",
    "# result_mlqa_dataset_mlqa_student_unsup = run_online_prompt_mining(mlqa_dataset['test'],\n",
    "#                          prefix='dataset-mlqa-en_model-mlqa_student_unsup',\n",
    "#                          model=mlqa_student_unsupported_langs_model)\n",
    "\n",
    "# result_mlqa_dataset_xorqa_student_sup = run_online_prompt_mining(mlqa_dataset['test'],\n",
    "#                          prefix='dataset-mlqa-en_model-xorqa_student_sup',\n",
    "#                          model=xorqa_student_supported_langs_model)\n",
    "# result_mlqa_dataset_xorqa_student_unsup = run_online_prompt_mining(mlqa_dataset['test'],\n",
    "#                          prefix='dataset-mlqa-en_model-xorqa_student_unsup',\n",
    "#                          model=xorqa_student_unsupported_langs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) XORQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "XORQA_BASE_DIR = '../data/xorqa/en/tydi_xor_gp/'\n",
    "xorqa_xx = {\n",
    "    'train': json.load(open(os.path.join(XORQA_BASE_DIR, 'gp_squad_train_data.json'), 'r'))['data'],\n",
    "      'val': json.load(open(os.path.join(XORQA_BASE_DIR, 'gp_squad_dev_data.json'), 'r'))['data'],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'title:Vamsy_parentSection:Introduction_sectionName:Career._sectionIndex:2',\n",
       " 'paragraphs': [{'context': 'He has published a short stories compilation called \"Maa Pasalapudi Kathalu\". Besides that compilation, Vamsy has written a wide variety of short stories since 1974 when he was 18 years old. His major works include \"Mahallo kokila\", \"Manchupallaki\", \"Aa Naati Vaana Chinukulu\", \"Venditera Kathalu\" (original scripts of \"Sankarabharanam\" and \"Anveshana\"), \"Vennela Bomma\", \"Gokulam lo Radha\", \"Ravvala konda\", \"Sree seetarama lanchi service Rajahmundry\", \"Manyam rani\", \"Rangularatnam\". He has penned around 150 short stories published in swathi weekly under title \"Maa Diguwa Godavari Kathalu\" For his contributions to the art of story telling with a native approach through his books he was bestowed with \"Sripada Puraskhaaram\" at Rajamundry on 17 April 2011.',\n",
       "   'qas': [{'question': 'మా పసలపూడి కథలు పుస్తకమును ఎవరు రచించారు?',\n",
       "     'answers': [{'text': 'Vamsy', 'answer_start': 104}],\n",
       "     'id': '-107019484199702154',\n",
       "     'lang': 'te',\n",
       "     'split': 'train'}]}]}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_xx['train'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'title:Orlov Trotter_parentSection:Introduction_sectionName:Development of the breed._sectionIndex:2',\n",
       " 'paragraphs': [{'context': 'Polkan was crossed with a Dutch mare which, in 1784, produced the grey stallion Bars I (1784–1808), considered the first Orlov trotter. He was 162.5 cm high at the withers which made him taller than most contemporary trotters, possessed a fast trotting gait and featured the beauty and noble bearing which would later distinguish the newly created breed. For seventeen years Bars I was crossed with different mares and sired eleven stallions that carried his distinguishing characteristics. The emergence of the breed was the result of a thorough and elaborate selection process. About 3,000 horses kept at the stud were involved. Unlike many other Russian nobles who were fond of horse-raising, Orlov was a professional breeder who is also credited for creating some seventy different animal breeds including the Russian wolfhound.',\n",
       "   'qas': [{'question': 'Какова высота в холке орловских рысаков?',\n",
       "     'answers': [{'text': '162.5 cm', 'answer_start': 143}],\n",
       "     'id': '657941441156344475',\n",
       "     'lang': 'ru',\n",
       "     'split': 'dev'}]}]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_xx['val'][-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xorqa_answer_str(context, qas):\n",
    "    context_qa_pairs = []\n",
    "    for qa in qas:\n",
    "        question = qa['question']\n",
    "        lang = qa['lang']\n",
    "        answer = qa['answers'][0]['text']\n",
    "        answer_start = qa['answers'][0]['answer_start']\n",
    "        context_qa_pairs.append((context, question, answer, answer_start, lang))\n",
    "    return context_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "xorqa_xx_dataset = defaultdict(lambda: { 'train': [], 'val': [] })\n",
    "\n",
    "for split_name in ['train', 'val']:\n",
    "    for i, item in enumerate(xorqa_xx[split_name]):\n",
    "        paragraphs = item['paragraphs']\n",
    "#         print('.' ,end='')\n",
    "        for j, paragraph in enumerate(paragraphs):\n",
    "\n",
    "            context = paragraph['context']\n",
    "            context_qa_pairs = get_xorqa_answer_str(context=context, qas=paragraph['qas'])\n",
    "\n",
    "            for context_qa_pair in context_qa_pairs:\n",
    "                context, question, answer, answer_start, lang = context_qa_pair\n",
    "                gt_sentence = mine_prompt_gt((context, question, answer, answer_start))\n",
    "                qa_item = {\n",
    "                     'question': question,\n",
    "                     'lang': lang,\n",
    "                     'context': context,\n",
    "                     'segmented_context': segment_sentence(context),\n",
    "                     'answer': answer,\n",
    "                     'answer_start': answer_start,\n",
    "                     'gt_sentence': gt_sentence,\n",
    "                }\n",
    "                xorqa_xx_dataset[lang][split_name].append(qa_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bn', 'ja', 'ko', 'ru', 'fi', ' ar', 'te', 'ar']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(xorqa_xx_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xorqa_xx_dataset['ar']['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full loop\n",
    " \n",
    " ```\n",
    " results = {\n",
    "     'dataset-name':\n",
    "         {\n",
    "             'model-name':\n",
    "\n",
    "                 [] # dataset retrieval results\n",
    "         }\n",
    " }\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAPPING = {\n",
    "#   'model-xquad_student_supported_langs': xquad_student_supported_langs_model,\n",
    "#   'model-xorqa_student_supported_langs': xorqa_student_supported_langs_model,\n",
    "#   'model-mlqa_student_supported_langs': mlqa_student_supported_langs_model,\n",
    "#   'model-xquad_student_unsupported_langs': xquad_student_unsupported_langs_model,\n",
    "#   'model-xorqa_student_unsupported_langs': xorqa_student_unsupported_langs_model,\n",
    "#   'model-mlqa_student_unsupported_langs': mlqa_student_unsupported_langs_model,\n",
    "#   'model-muse_small_v3': muse_small_v3_model,\n",
    "  'model-xquad_teacher': xquad_teacher_model,\n",
    "#   'model-xorqa_teacher': xorqa_teacher_model,\n",
    "  'model-mlqa_teacher': mlqa_teacher_model,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dataset-xquad_en_train', 'dataset-xorqa_bn_train', 'dataset-xorqa_bn_val', 'dataset-xorqa_ja_train', 'dataset-xorqa_ja_val', 'dataset-xorqa_ko_train', 'dataset-xorqa_ko_val', 'dataset-xorqa_ru_train', 'dataset-xorqa_ru_val', 'dataset-xorqa_fi_train', 'dataset-xorqa_fi_val', 'dataset-xorqa_ar_train', 'dataset-xorqa_te_train', 'dataset-xorqa_te_val', 'dataset-xorqa_ar_val', 'dataset-mlqa_en_val', 'dataset-mlqa_en_test', 'dataset-mlqa_ar_val', 'dataset-mlqa_ar_test', 'dataset-mlqa_de_val', 'dataset-mlqa_de_test', 'dataset-mlqa_es_val', 'dataset-mlqa_es_test', 'dataset-mlqa_hi_val', 'dataset-mlqa_hi_test', 'dataset-mlqa_vi_val', 'dataset-mlqa_vi_test', 'dataset-mlqa_zh_val', 'dataset-mlqa_zh_test'])\n"
     ]
    }
   ],
   "source": [
    "DATASET_MAPPING = {\n",
    "    'dataset-xquad_en_train': xquad_dataset,\n",
    "}\n",
    "\n",
    "for lang in list(xorqa_xx_dataset.keys()):\n",
    "    if len(xorqa_xx_dataset[lang]['train']) != 0:\n",
    "        DATASET_MAPPING[f'dataset-xorqa_{lang.strip()}_train'] = xorqa_xx_dataset[lang]['train']\n",
    "    if len(xorqa_xx_dataset[lang]['val']) != 0:\n",
    "        DATASET_MAPPING[f'dataset-xorqa_{lang.strip()}_val'] = xorqa_xx_dataset[lang]['val']\n",
    "\n",
    "for lang in list(MLQA_LANGS):\n",
    "    DATASET_MAPPING[f'dataset-mlqa_{lang.strip()}_val'] = mlqa_xx_dataset[lang]['val']\n",
    "    DATASET_MAPPING[f'dataset-mlqa_{lang.strip()}_test'] = mlqa_xx_dataset[lang]['test']\n",
    "    \n",
    "print(DATASET_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DATASET_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(lambda: defaultdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dataset_prefix: dataset-xquad_en_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1190/1190 [00:30<00:00, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7160\n",
      "\t - precision_at_k:\n",
      "{1: 0.7159663865546219,\n",
      " 2: 0.8789915966386554,\n",
      " 3: 0.9352941176470588,\n",
      " 4: 0.9714285714285714,\n",
      " 5: 0.9882352941176471,\n",
      " 6: 0.9932773109243698,\n",
      " 7: 0.9957983193277311,\n",
      " 8: 0.9966386554621849,\n",
      " 9: 0.9974789915966387,\n",
      " 10: 0.9974789915966387}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1190/1190 [00:26<00:00, 44.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7319\n",
      "\t - precision_at_k:\n",
      "{1: 0.7319327731092437,\n",
      " 2: 0.8798319327731092,\n",
      " 3: 0.9411764705882353,\n",
      " 4: 0.9773109243697479,\n",
      " 5: 0.9907563025210084,\n",
      " 6: 0.9932773109243698,\n",
      " 7: 0.9957983193277311,\n",
      " 8: 0.9966386554621849,\n",
      " 9: 0.9983193277310924,\n",
      " 10: 0.9983193277310924}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_bn_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2474/2474 [00:45<00:00, 54.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3868\n",
      "\t - precision_at_k:\n",
      "{1: 0.3868229587712207,\n",
      " 2: 0.6329830234438156,\n",
      " 3: 0.778496362166532,\n",
      " 4: 0.8779304769603881,\n",
      " 5: 0.9236054971705739,\n",
      " 6: 0.9583670169765561,\n",
      " 7: 0.9737267582861763,\n",
      " 8: 0.9834276475343573,\n",
      " 9: 0.9878738884397736,\n",
      " 10: 0.9907033144704931}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2474/2474 [00:46<00:00, 53.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4228\n",
      "\t - precision_at_k:\n",
      "{1: 0.42279708973322555,\n",
      " 2: 0.650767987065481,\n",
      " 3: 0.7922392886014551,\n",
      " 4: 0.8811641067097817,\n",
      " 5: 0.9284559417946645,\n",
      " 6: 0.9595796281325788,\n",
      " 7: 0.9753435731608731,\n",
      " 8: 0.9810024252223121,\n",
      " 9: 0.9886822958771221,\n",
      " 10: 0.99232012934519}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_bn_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 523/523 [00:08<00:00, 63.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3996\n",
      "\t - precision_at_k:\n",
      "{1: 0.39961759082217974,\n",
      " 2: 0.6749521988527725,\n",
      " 3: 0.8107074569789675,\n",
      " 4: 0.8833652007648184,\n",
      " 5: 0.9311663479923518,\n",
      " 6: 0.9694072657743786,\n",
      " 7: 0.9770554493307839,\n",
      " 8: 0.9847036328871893,\n",
      " 9: 0.994263862332696,\n",
      " 10: 0.9961759082217974}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 523/523 [00:08<00:00, 61.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4589\n",
      "\t - precision_at_k:\n",
      "{1: 0.4588910133843212,\n",
      " 2: 0.6998087954110899,\n",
      " 3: 0.8393881453154876,\n",
      " 4: 0.9139579349904398,\n",
      " 5: 0.9560229445506692,\n",
      " 6: 0.9694072657743786,\n",
      " 7: 0.9847036328871893,\n",
      " 8: 0.9866156787762906,\n",
      " 9: 0.9904397705544933,\n",
      " 10: 0.9961759082217974}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ja_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1927/1927 [00:31<00:00, 61.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4982\n",
      "\t - precision_at_k:\n",
      "{1: 0.49818370524130773,\n",
      " 2: 0.742086144265698,\n",
      " 3: 0.8785677218474313,\n",
      " 4: 0.934094447327452,\n",
      " 5: 0.9615983393876492,\n",
      " 6: 0.9792423456149455,\n",
      " 7: 0.987026466009341,\n",
      " 8: 0.9922158796056045,\n",
      " 9: 0.9963674104826155,\n",
      " 10: 0.9979242345614946}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1927/1927 [00:32<00:00, 59.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5189\n",
      "\t - precision_at_k:\n",
      "{1: 0.5189413596263622,\n",
      " 2: 0.7633627400103788,\n",
      " 3: 0.8879086663207058,\n",
      " 4: 0.9403217436429684,\n",
      " 5: 0.9683445770627919,\n",
      " 6: 0.9823559937727037,\n",
      " 7: 0.987026466009341,\n",
      " 8: 0.9922158796056045,\n",
      " 9: 0.9953295277633627,\n",
      " 10: 0.9989621172807472}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ja_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 371/371 [00:06<00:00, 58.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5013\n",
      "\t - precision_at_k:\n",
      "{1: 0.5013477088948787,\n",
      " 2: 0.7628032345013477,\n",
      " 3: 0.8975741239892183,\n",
      " 4: 0.967654986522911,\n",
      " 5: 0.9838274932614556,\n",
      " 6: 0.9892183288409704,\n",
      " 7: 0.9946091644204852,\n",
      " 8: 0.9946091644204852,\n",
      " 9: 0.9946091644204852,\n",
      " 10: 0.9946091644204852}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 371/371 [00:06<00:00, 60.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5067\n",
      "\t - precision_at_k:\n",
      "{1: 0.5067385444743935,\n",
      " 2: 0.7789757412398922,\n",
      " 3: 0.9137466307277629,\n",
      " 4: 0.9622641509433962,\n",
      " 5: 0.9838274932614556,\n",
      " 6: 0.9865229110512129,\n",
      " 7: 0.9946091644204852,\n",
      " 8: 0.9946091644204852,\n",
      " 9: 0.9946091644204852,\n",
      " 10: 0.9946091644204852}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ko_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2395/2395 [00:38<00:00, 61.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5340\n",
      "\t - precision_at_k:\n",
      "{1: 0.5340292275574112,\n",
      " 2: 0.7812108559498956,\n",
      " 3: 0.8960334029227558,\n",
      " 4: 0.9490605427974947,\n",
      " 5: 0.9703549060542798,\n",
      " 6: 0.9832985386221295,\n",
      " 7: 0.9895615866388309,\n",
      " 8: 0.9945720250521921,\n",
      " 9: 0.9966597077244259,\n",
      " 10: 0.9966597077244259}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2395/2395 [00:38<00:00, 62.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5574\n",
      "\t - precision_at_k:\n",
      "{1: 0.55741127348643,\n",
      " 2: 0.7870563674321504,\n",
      " 3: 0.904384133611691,\n",
      " 4: 0.9519832985386222,\n",
      " 5: 0.9736951983298539,\n",
      " 6: 0.9874739039665971,\n",
      " 7: 0.9912317327766179,\n",
      " 8: 0.9941544885177453,\n",
      " 9: 0.9958246346555324,\n",
      " 10: 0.9966597077244259}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ko_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 460/460 [00:07<00:00, 62.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5087\n",
      "\t - precision_at_k:\n",
      "{1: 0.508695652173913,\n",
      " 2: 0.7478260869565218,\n",
      " 3: 0.8695652173913043,\n",
      " 4: 0.9478260869565217,\n",
      " 5: 0.9804347826086957,\n",
      " 6: 0.9869565217391304,\n",
      " 7: 0.9956521739130435,\n",
      " 8: 0.9956521739130435,\n",
      " 9: 0.9956521739130435,\n",
      " 10: 0.9956521739130435}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 460/460 [00:07<00:00, 62.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5239\n",
      "\t - precision_at_k:\n",
      "{1: 0.5239130434782608,\n",
      " 2: 0.7608695652173914,\n",
      " 3: 0.8913043478260869,\n",
      " 4: 0.9565217391304348,\n",
      " 5: 0.9804347826086957,\n",
      " 6: 0.9891304347826086,\n",
      " 7: 0.9956521739130435,\n",
      " 8: 0.9956521739130435,\n",
      " 9: 0.9956521739130435,\n",
      " 10: 0.9956521739130435}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ru_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1744/1744 [00:28<00:00, 60.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5315\n",
      "\t - precision_at_k:\n",
      "{1: 0.5315366972477065,\n",
      " 2: 0.7557339449541285,\n",
      " 3: 0.8864678899082569,\n",
      " 4: 0.9409403669724771,\n",
      " 5: 0.9655963302752294,\n",
      " 6: 0.9776376146788991,\n",
      " 7: 0.989105504587156,\n",
      " 8: 0.9948394495412844,\n",
      " 9: 0.9965596330275229,\n",
      " 10: 0.9971330275229358}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1744/1744 [00:28<00:00, 61.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5396\n",
      "\t - precision_at_k:\n",
      "{1: 0.5395642201834863,\n",
      " 2: 0.7677752293577982,\n",
      " 3: 0.8916284403669725,\n",
      " 4: 0.9415137614678899,\n",
      " 5: 0.9673165137614679,\n",
      " 6: 0.9799311926605505,\n",
      " 7: 0.9896788990825688,\n",
      " 8: 0.9931192660550459,\n",
      " 9: 0.9954128440366973,\n",
      " 10: 0.9971330275229358}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ru_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 384/384 [00:06<00:00, 59.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5938\n",
      "\t - precision_at_k:\n",
      "{1: 0.59375,\n",
      " 2: 0.8098958333333334,\n",
      " 3: 0.890625,\n",
      " 4: 0.9609375,\n",
      " 5: 0.9895833333333334,\n",
      " 6: 0.9973958333333334,\n",
      " 7: 0.9973958333333334,\n",
      " 8: 1.0,\n",
      " 9: 1.0,\n",
      " 10: 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 384/384 [00:06<00:00, 56.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6146\n",
      "\t - precision_at_k:\n",
      "{1: 0.6145833333333334,\n",
      " 2: 0.8020833333333334,\n",
      " 3: 0.8984375,\n",
      " 4: 0.9557291666666666,\n",
      " 5: 0.9817708333333334,\n",
      " 6: 0.9947916666666666,\n",
      " 7: 1.0,\n",
      " 8: 1.0,\n",
      " 9: 1.0,\n",
      " 10: 1.0}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_fi_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1855/1855 [00:30<00:00, 60.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4189\n",
      "\t - precision_at_k:\n",
      "{1: 0.4188679245283019,\n",
      " 2: 0.6619946091644204,\n",
      " 3: 0.8037735849056604,\n",
      " 4: 0.8857142857142857,\n",
      " 5: 0.9369272237196765,\n",
      " 6: 0.9644204851752022,\n",
      " 7: 0.9730458221024259,\n",
      " 8: 0.982210242587601,\n",
      " 9: 0.9865229110512129,\n",
      " 10: 0.9908355795148248}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1855/1855 [00:30<00:00, 60.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4350\n",
      "\t - precision_at_k:\n",
      "{1: 0.4350404312668464,\n",
      " 2: 0.6711590296495957,\n",
      " 3: 0.8177897574123989,\n",
      " 4: 0.8889487870619946,\n",
      " 5: 0.9401617250673855,\n",
      " 6: 0.9628032345013477,\n",
      " 7: 0.9730458221024259,\n",
      " 8: 0.9838274932614556,\n",
      " 9: 0.9865229110512129,\n",
      " 10: 0.9908355795148248}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_fi_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 509/509 [00:09<00:00, 55.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3576\n",
      "\t - precision_at_k:\n",
      "{1: 0.3575638506876228,\n",
      " 2: 0.5913555992141454,\n",
      " 3: 0.8133595284872298,\n",
      " 4: 0.9017681728880157,\n",
      " 5: 0.9567779960707269,\n",
      " 6: 0.9685658153241651,\n",
      " 7: 0.9744597249508841,\n",
      " 8: 0.9803536345776032,\n",
      " 9: 0.9941060903732809,\n",
      " 10: 0.9960707269155207}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 509/509 [00:08<00:00, 59.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3870\n",
      "\t - precision_at_k:\n",
      "{1: 0.38703339882121807,\n",
      " 2: 0.6345776031434185,\n",
      " 3: 0.8172888015717092,\n",
      " 4: 0.9076620825147348,\n",
      " 5: 0.9469548133595285,\n",
      " 6: 0.9666011787819253,\n",
      " 7: 0.9783889980353635,\n",
      " 8: 0.9842829076620825,\n",
      " 9: 0.9921414538310412,\n",
      " 10: 0.9941060903732809}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ar_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2303/2303 [00:38<00:00, 59.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5119\n",
      "\t - precision_at_k:\n",
      "{1: 0.5119409465914025,\n",
      " 2: 0.756838905775076,\n",
      " 3: 0.8679982631350412,\n",
      " 4: 0.9366044290056448,\n",
      " 5: 0.9617889709075119,\n",
      " 6: 0.9774207555362571,\n",
      " 7: 0.9848024316109423,\n",
      " 8: 0.9874077290490665,\n",
      " 9: 0.9887103777681285,\n",
      " 10: 0.9908814589665653}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2303/2303 [00:39<00:00, 58.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5332\n",
      "\t - precision_at_k:\n",
      "{1: 0.5332175423360833,\n",
      " 2: 0.7694311767260096,\n",
      " 3: 0.8745115067303517,\n",
      " 4: 0.9409465914025185,\n",
      " 5: 0.9661311333043856,\n",
      " 6: 0.9791576204950065,\n",
      " 7: 0.9848024316109423,\n",
      " 8: 0.9887103777681285,\n",
      " 9: 0.9908814589665653,\n",
      " 10: 0.9921841076856275}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_te_train\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1305/1305 [00:20<00:00, 62.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3625\n",
      "\t - precision_at_k:\n",
      "{1: 0.3624521072796935,\n",
      " 2: 0.6091954022988506,\n",
      " 3: 0.7793103448275862,\n",
      " 4: 0.8804597701149425,\n",
      " 5: 0.9425287356321839,\n",
      " 6: 0.9724137931034482,\n",
      " 7: 0.9808429118773946,\n",
      " 8: 0.9831417624521073,\n",
      " 9: 0.993103448275862,\n",
      " 10: 0.9954022988505747}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1305/1305 [00:20<00:00, 63.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3824\n",
      "\t - precision_at_k:\n",
      "{1: 0.3823754789272031,\n",
      " 2: 0.6444444444444445,\n",
      " 3: 0.782375478927203,\n",
      " 4: 0.8881226053639847,\n",
      " 5: 0.9425287356321839,\n",
      " 6: 0.9670498084291188,\n",
      " 7: 0.9793103448275862,\n",
      " 8: 0.9869731800766284,\n",
      " 9: 0.9915708812260536,\n",
      " 10: 0.9961685823754789}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_te_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 376/376 [00:06<00:00, 60.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3936\n",
      "\t - precision_at_k:\n",
      "{1: 0.39361702127659576,\n",
      " 2: 0.601063829787234,\n",
      " 3: 0.7952127659574468,\n",
      " 4: 0.8776595744680851,\n",
      " 5: 0.9069148936170213,\n",
      " 6: 0.9680851063829787,\n",
      " 7: 0.9813829787234043,\n",
      " 8: 0.9867021276595744,\n",
      " 9: 0.9867021276595744,\n",
      " 10: 0.9867021276595744}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 376/376 [00:06<00:00, 60.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3644\n",
      "\t - precision_at_k:\n",
      "{1: 0.36436170212765956,\n",
      " 2: 0.6276595744680851,\n",
      " 3: 0.7792553191489362,\n",
      " 4: 0.8723404255319149,\n",
      " 5: 0.9441489361702128,\n",
      " 6: 0.9680851063829787,\n",
      " 7: 0.973404255319149,\n",
      " 8: 0.9840425531914894,\n",
      " 9: 0.9867021276595744,\n",
      " 10: 0.9893617021276596}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_ar_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:08<00:00, 59.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5216\n",
      "\t - precision_at_k:\n",
      "{1: 0.5216494845360825,\n",
      " 2: 0.7381443298969073,\n",
      " 3: 0.8762886597938144,\n",
      " 4: 0.931958762886598,\n",
      " 5: 0.9628865979381444,\n",
      " 6: 0.9731958762886598,\n",
      " 7: 0.9835051546391752,\n",
      " 8: 0.9876288659793815,\n",
      " 9: 0.9896907216494846,\n",
      " 10: 0.9917525773195877}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 485/485 [00:07<00:00, 65.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.5629\n",
      "\t - precision_at_k:\n",
      "{1: 0.5628865979381443,\n",
      " 2: 0.7587628865979381,\n",
      " 3: 0.8845360824742268,\n",
      " 4: 0.931958762886598,\n",
      " 5: 0.9690721649484536,\n",
      " 6: 0.979381443298969,\n",
      " 7: 0.9814432989690721,\n",
      " 8: 0.9855670103092784,\n",
      " 9: 0.9896907216494846,\n",
      " 10: 0.9917525773195877}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_en_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1148/1148 [00:22<00:00, 50.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7247\n",
      "\t - precision_at_k:\n",
      "{1: 0.7247386759581882,\n",
      " 2: 0.8641114982578397,\n",
      " 3: 0.9259581881533101,\n",
      " 4: 0.9494773519163763,\n",
      " 5: 0.9651567944250871,\n",
      " 6: 0.975609756097561,\n",
      " 7: 0.985191637630662,\n",
      " 8: 0.9878048780487805,\n",
      " 9: 0.9895470383275261,\n",
      " 10: 0.9921602787456446}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1148/1148 [00:22<00:00, 51.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7265\n",
      "\t - precision_at_k:\n",
      "{1: 0.7264808362369338,\n",
      " 2: 0.8693379790940766,\n",
      " 3: 0.9233449477351916,\n",
      " 4: 0.9494773519163763,\n",
      " 5: 0.9651567944250871,\n",
      " 6: 0.9747386759581882,\n",
      " 7: 0.9817073170731707,\n",
      " 8: 0.990418118466899,\n",
      " 9: 0.9912891986062717,\n",
      " 10: 0.9930313588850174}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_en_test\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11590/11590 [04:03<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7035\n",
      "\t - precision_at_k:\n",
      "{1: 0.7035375323554789,\n",
      " 2: 0.8440897325280414,\n",
      " 3: 0.9097497842968076,\n",
      " 4: 0.9440034512510785,\n",
      " 5: 0.962381363244176,\n",
      " 6: 0.9715271786022434,\n",
      " 7: 0.9805004314063848,\n",
      " 8: 0.9858498705780846,\n",
      " 9: 0.9885245901639345,\n",
      " 10: 0.991458153580673}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11590/11590 [04:30<00:00, 42.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7112\n",
      "\t - precision_at_k:\n",
      "{1: 0.7112165660051769,\n",
      " 2: 0.8484037963761863,\n",
      " 3: 0.9101811906816221,\n",
      " 4: 0.9446937014667817,\n",
      " 5: 0.9602243313201035,\n",
      " 6: 0.9715271786022434,\n",
      " 7: 0.980327868852459,\n",
      " 8: 0.9855910267471959,\n",
      " 9: 0.9891285591026747,\n",
      " 10: 0.9904227782571182}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_ar_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [00:10<00:00, 48.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6538\n",
      "\t - precision_at_k:\n",
      "{1: 0.6537717601547389,\n",
      " 2: 0.816247582205029,\n",
      " 3: 0.8936170212765957,\n",
      " 4: 0.9342359767891683,\n",
      " 5: 0.9497098646034816,\n",
      " 6: 0.9632495164410058,\n",
      " 7: 0.97678916827853,\n",
      " 8: 0.9825918762088974,\n",
      " 9: 0.988394584139265,\n",
      " 10: 0.9922630560928434}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 517/517 [00:12<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6634\n",
      "\t - precision_at_k:\n",
      "{1: 0.6634429400386848,\n",
      " 2: 0.8278529980657641,\n",
      " 3: 0.8974854932301741,\n",
      " 4: 0.9226305609284333,\n",
      " 5: 0.9497098646034816,\n",
      " 6: 0.9690522243713733,\n",
      " 7: 0.9787234042553191,\n",
      " 8: 0.9825918762088974,\n",
      " 9: 0.9903288201160542,\n",
      " 10: 0.9941972920696325}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_ar_test\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5335/5335 [02:08<00:00, 41.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6343\n",
      "\t - precision_at_k:\n",
      "{1: 0.6343017806935333,\n",
      " 2: 0.8031865042174321,\n",
      " 3: 0.8877225866916588,\n",
      " 4: 0.9244611059044049,\n",
      " 5: 0.9471415182755389,\n",
      " 6: 0.9606373008434864,\n",
      " 7: 0.971883786316776,\n",
      " 8: 0.9814432989690721,\n",
      " 9: 0.9861293345829428,\n",
      " 10: 0.9887535145267105}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5335/5335 [02:06<00:00, 42.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6521\n",
      "\t - precision_at_k:\n",
      "{1: 0.6521087160262418,\n",
      " 2: 0.814058106841612,\n",
      " 3: 0.8894095595126523,\n",
      " 4: 0.9257731958762887,\n",
      " 5: 0.9475164011246485,\n",
      " 6: 0.9613870665417057,\n",
      " 7: 0.9709465791940018,\n",
      " 8: 0.9806935332708528,\n",
      " 9: 0.9861293345829428,\n",
      " 10: 0.98912839737582}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_de_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:12<00:00, 40.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7051\n",
      "\t - precision_at_k:\n",
      "{1: 0.705078125,\n",
      " 2: 0.849609375,\n",
      " 3: 0.91796875,\n",
      " 4: 0.94921875,\n",
      " 5: 0.9609375,\n",
      " 6: 0.96875,\n",
      " 7: 0.978515625,\n",
      " 8: 0.982421875,\n",
      " 9: 0.986328125,\n",
      " 10: 0.986328125}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:12<00:00, 41.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7090\n",
      "\t - precision_at_k:\n",
      "{1: 0.708984375,\n",
      " 2: 0.85546875,\n",
      " 3: 0.919921875,\n",
      " 4: 0.939453125,\n",
      " 5: 0.955078125,\n",
      " 6: 0.966796875,\n",
      " 7: 0.9765625,\n",
      " 8: 0.982421875,\n",
      " 9: 0.98828125,\n",
      " 10: 0.98828125}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_de_test\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4517/4517 [01:52<00:00, 40.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6719\n",
      "\t - precision_at_k:\n",
      "{1: 0.6719061323887536,\n",
      " 2: 0.8246623865397388,\n",
      " 3: 0.8968341819791897,\n",
      " 4: 0.9340270090768209,\n",
      " 5: 0.9521806508744742,\n",
      " 6: 0.9670135045384104,\n",
      " 7: 0.9760903254372371,\n",
      " 8: 0.9825105158290901,\n",
      " 9: 0.9851671463360637,\n",
      " 10: 0.9895948638476865}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4517/4517 [01:55<00:00, 39.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6783\n",
      "\t - precision_at_k:\n",
      "{1: 0.6783263227806066,\n",
      " 2: 0.8308611910560106,\n",
      " 3: 0.8968341819791897,\n",
      " 4: 0.9344697808279832,\n",
      " 5: 0.9526234226256365,\n",
      " 6: 0.9659065751605047,\n",
      " 7: 0.9760903254372371,\n",
      " 8: 0.980739428824441,\n",
      " 9: 0.9867168474651318,\n",
      " 10: 0.988709320345362}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_es_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:11<00:00, 42.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7020\n",
      "\t - precision_at_k:\n",
      "{1: 0.702,\n",
      " 2: 0.85,\n",
      " 3: 0.918,\n",
      " 4: 0.95,\n",
      " 5: 0.966,\n",
      " 6: 0.974,\n",
      " 7: 0.978,\n",
      " 8: 0.984,\n",
      " 9: 0.99,\n",
      " 10: 0.992}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:12<00:00, 39.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7100\n",
      "\t - precision_at_k:\n",
      "{1: 0.71,\n",
      " 2: 0.864,\n",
      " 3: 0.918,\n",
      " 4: 0.952,\n",
      " 5: 0.972,\n",
      " 6: 0.974,\n",
      " 7: 0.98,\n",
      " 8: 0.986,\n",
      " 9: 0.992,\n",
      " 10: 0.992}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_es_test\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5253/5253 [02:21<00:00, 37.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6787\n",
      "\t - precision_at_k:\n",
      "{1: 0.6786598134399391,\n",
      " 2: 0.8347610889015801,\n",
      " 3: 0.905197030268418,\n",
      " 4: 0.9369883875880449,\n",
      " 5: 0.9565962307252999,\n",
      " 6: 0.972206358271464,\n",
      " 7: 0.9805825242718447,\n",
      " 8: 0.9851513420902341,\n",
      " 9: 0.9885779554540263,\n",
      " 10: 0.9906719969541214}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5253/5253 [02:13<00:00, 39.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6901\n",
      "\t - precision_at_k:\n",
      "{1: 0.6900818579859128,\n",
      " 2: 0.8387588044926708,\n",
      " 3: 0.9008185798591282,\n",
      " 4: 0.9371787549971445,\n",
      " 5: 0.9588806396344945,\n",
      " 6: 0.9712545212259661,\n",
      " 7: 0.9813439939082429,\n",
      " 8: 0.984770607272035,\n",
      " 9: 0.9889586902722254,\n",
      " 10: 0.9906719969541214}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_hi_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 507/507 [00:11<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.2880\n",
      "\t - precision_at_k:\n",
      "{1: 0.2879684418145957,\n",
      " 2: 0.48520710059171596,\n",
      " 3: 0.6390532544378699,\n",
      " 4: 0.7554240631163708,\n",
      " 5: 0.8264299802761341,\n",
      " 6: 0.863905325443787,\n",
      " 7: 0.8915187376725838,\n",
      " 8: 0.903353057199211,\n",
      " 9: 0.9171597633136095,\n",
      " 10: 0.9447731755424064}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 507/507 [00:11<00:00, 42.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3176\n",
      "\t - precision_at_k:\n",
      "{1: 0.3175542406311637,\n",
      " 2: 0.4930966469428008,\n",
      " 3: 0.6390532544378699,\n",
      " 4: 0.7337278106508875,\n",
      " 5: 0.8205128205128205,\n",
      " 6: 0.8520710059171598,\n",
      " 7: 0.8796844181459567,\n",
      " 8: 0.8994082840236687,\n",
      " 9: 0.9211045364891519,\n",
      " 10: 0.9270216962524654}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_hi_test\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4918/4918 [02:03<00:00, 39.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.2597\n",
      "\t - precision_at_k:\n",
      "{1: 0.2596583977226515,\n",
      " 2: 0.4522163481089874,\n",
      " 3: 0.5927206181374542,\n",
      " 4: 0.6966246441642945,\n",
      " 5: 0.7720618137454249,\n",
      " 6: 0.8259455063033754,\n",
      " 7: 0.865189101260675,\n",
      " 8: 0.892842618950793,\n",
      " 9: 0.9143960959739732,\n",
      " 10: 0.9300528670191135}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4918/4918 [02:03<00:00, 39.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.2631\n",
      "\t - precision_at_k:\n",
      "{1: 0.2631150874339162,\n",
      " 2: 0.45404636030906875,\n",
      " 3: 0.5892639284261895,\n",
      " 4: 0.695201301342009,\n",
      " 5: 0.7686051240341603,\n",
      " 6: 0.8190321268808459,\n",
      " 7: 0.8609190727938186,\n",
      " 8: 0.8899959333062221,\n",
      " 9: 0.9107360715738105,\n",
      " 10: 0.9296461976413176}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_vi_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 511/511 [00:14<00:00, 35.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3542\n",
      "\t - precision_at_k:\n",
      "{1: 0.3542074363992172,\n",
      " 2: 0.5225048923679061,\n",
      " 3: 0.6868884540117417,\n",
      " 4: 0.7808219178082192,\n",
      " 5: 0.837573385518591,\n",
      " 6: 0.8904109589041096,\n",
      " 7: 0.9080234833659491,\n",
      " 8: 0.9275929549902152,\n",
      " 9: 0.9432485322896281,\n",
      " 10: 0.9452054794520548}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 511/511 [00:12<00:00, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3659\n",
      "\t - precision_at_k:\n",
      "{1: 0.3659491193737769,\n",
      " 2: 0.5362035225048923,\n",
      " 3: 0.6829745596868885,\n",
      " 4: 0.7788649706457925,\n",
      " 5: 0.8277886497064579,\n",
      " 6: 0.8767123287671232,\n",
      " 7: 0.9099804305283757,\n",
      " 8: 0.9275929549902152,\n",
      " 9: 0.9432485322896281,\n",
      " 10: 0.9452054794520548}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_vi_test\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5495/5495 [02:24<00:00, 38.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3480\n",
      "\t - precision_at_k:\n",
      "{1: 0.34795268425841674,\n",
      " 2: 0.5339399454049135,\n",
      " 3: 0.6611464968152866,\n",
      " 4: 0.7477707006369426,\n",
      " 5: 0.8065514103730664,\n",
      " 6: 0.8493175614194722,\n",
      " 7: 0.8780709736123748,\n",
      " 8: 0.9020928116469518,\n",
      " 9: 0.9233848953594177,\n",
      " 10: 0.9390354868061874}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5495/5495 [02:24<00:00, 38.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3576\n",
      "\t - precision_at_k:\n",
      "{1: 0.3575978161965423,\n",
      " 2: 0.5306642402183803,\n",
      " 3: 0.6518653321201092,\n",
      " 4: 0.7392174704276615,\n",
      " 5: 0.8007279344858963,\n",
      " 6: 0.8445859872611465,\n",
      " 7: 0.8751592356687898,\n",
      " 8: 0.902820746132848,\n",
      " 9: 0.9219290263876251,\n",
      " 10: 0.937943585077343}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_zh_val\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 504/504 [00:12<00:00, 40.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6865\n",
      "\t - precision_at_k:\n",
      "{1: 0.6865079365079365,\n",
      " 2: 0.8253968253968254,\n",
      " 3: 0.8988095238095238,\n",
      " 4: 0.9305555555555556,\n",
      " 5: 0.9464285714285714,\n",
      " 6: 0.9682539682539683,\n",
      " 7: 0.9761904761904762,\n",
      " 8: 0.9821428571428571,\n",
      " 9: 0.9861111111111112,\n",
      " 10: 0.9880952380952381}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 504/504 [00:12<00:00, 41.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6925\n",
      "\t - precision_at_k:\n",
      "{1: 0.6924603174603174,\n",
      " 2: 0.8313492063492064,\n",
      " 3: 0.9047619047619048,\n",
      " 4: 0.9384920634920635,\n",
      " 5: 0.9563492063492064,\n",
      " 6: 0.9662698412698413,\n",
      " 7: 0.9761904761904762,\n",
      " 8: 0.9841269841269841,\n",
      " 9: 0.9861111111111112,\n",
      " 10: 0.9880952380952381}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "dataset_prefix: dataset-mlqa_zh_test\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5137/5137 [02:13<00:00, 38.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6564\n",
      "\t - precision_at_k:\n",
      "{1: 0.6564142495620011,\n",
      " 2: 0.822075141132957,\n",
      " 3: 0.8907922912205567,\n",
      " 4: 0.9252481993381351,\n",
      " 5: 0.9501654662254234,\n",
      " 6: 0.9616507689312829,\n",
      " 7: 0.9717734086042438,\n",
      " 8: 0.9780027253260658,\n",
      " 9: 0.9836480436052171,\n",
      " 10: 0.9881253649990267}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5137/5137 [02:12<00:00, 38.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.6693\n",
      "\t - precision_at_k:\n",
      "{1: 0.6692622153007592,\n",
      " 2: 0.8288884562974499,\n",
      " 3: 0.8954642787619232,\n",
      " 4: 0.9285575238466031,\n",
      " 5: 0.9488028031925249,\n",
      " 6: 0.9624294335215106,\n",
      " 7: 0.9729414054895854,\n",
      " 8: 0.9781973914736227,\n",
      " 9: 0.9834533774576601,\n",
      " 10: 0.9873467004087989}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_prefix, dataset in DATASET_MAPPING.items():\n",
    "    print(f'\\n\\ndataset_prefix: {dataset_prefix}')\n",
    "    for model_prefix, model in MODEL_MAPPING.items():\n",
    "        \n",
    "        print(f'\\n - model_prefix: {model_prefix}')\n",
    "        prefix = f'{dataset_prefix}+{model_prefix}'\n",
    "        _result = run_online_prompt_mining(dataset,\n",
    "                             prefix=f'{dataset_prefix}_{model_prefix}',\n",
    "                             model=model)\n",
    "\n",
    "\n",
    "        results[dataset_prefix][model_prefix] = _result\n",
    "        print('--'*50)\n",
    "    print('\\n')    \n",
    "    print('=='*50)\n",
    "    print('\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results, open('./temp.results.model-teachers.json', 'w'), ensure_ascii=False, indent=2)\n",
    "\n",
    "# json.dump(results, open('./temp.results.mlqa-dataset-non-en.json', 'w'), ensure_ascii=False, indent=2)\n",
    "\n",
    "# json.dump(results, open('./temp.results.muse-small-v3.json', 'w'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
