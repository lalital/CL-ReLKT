{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-14T09:32:56.564473Z",
     "iopub.status.idle": "2022-06-14T09:32:56.564869Z",
     "shell.execute_reply": "2022-06-14T09:32:56.564718Z",
     "shell.execute_reply.started": "2022-06-14T09:32:56.564700Z"
    },
    "tags": []
   },
   "source": [
    "## Sentence-level online prompty mining: XORQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:24:30.769548Z",
     "iopub.status.busy": "2022-06-14T10:24:30.769276Z",
     "iopub.status.idle": "2022-06-14T10:24:30.773345Z",
     "shell.execute_reply": "2022-06-14T10:24:30.772778Z",
     "shell.execute_reply.started": "2022-06-14T10:24:30.769517Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import os, sys\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "from exploring_sentence_level import (\n",
    "    load_model,\n",
    "    mine_prompt_gt,  \n",
    "    segment_sentence,\n",
    "    run_online_prompt_mining\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Download dataset\n",
    "\n",
    "```bash\n",
    "cd ../scripts\n",
    "bash ./download_xorqa.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:24:39.821027Z",
     "iopub.status.busy": "2022-06-14T10:24:39.820738Z",
     "iopub.status.idle": "2022-06-14T10:24:40.025856Z",
     "shell.execute_reply": "2022-06-14T10:24:40.025050Z",
     "shell.execute_reply.started": "2022-06-14T10:24:39.820997Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "XORQA_BASE_DIR = '../data/xorqa/en/tydi_xor_gp/'\n",
    "xorqa_xx = {\n",
    "    'train': json.load(open(os.path.join(XORQA_BASE_DIR, 'gp_squad_train_data.json'), 'r'))['data'],\n",
    "      'val': json.load(open(os.path.join(XORQA_BASE_DIR, 'gp_squad_dev_data.json'), 'r'))['data'],   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:24:44.979844Z",
     "iopub.status.busy": "2022-06-14T10:24:44.979400Z",
     "iopub.status.idle": "2022-06-14T10:24:44.985010Z",
     "shell.execute_reply": "2022-06-14T10:24:44.984377Z",
     "shell.execute_reply.started": "2022-06-14T10:24:44.979814Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'title:Vamsy_parentSection:Introduction_sectionName:Career._sectionIndex:2',\n",
       " 'paragraphs': [{'context': 'He has published a short stories compilation called \"Maa Pasalapudi Kathalu\". Besides that compilation, Vamsy has written a wide variety of short stories since 1974 when he was 18 years old. His major works include \"Mahallo kokila\", \"Manchupallaki\", \"Aa Naati Vaana Chinukulu\", \"Venditera Kathalu\" (original scripts of \"Sankarabharanam\" and \"Anveshana\"), \"Vennela Bomma\", \"Gokulam lo Radha\", \"Ravvala konda\", \"Sree seetarama lanchi service Rajahmundry\", \"Manyam rani\", \"Rangularatnam\". He has penned around 150 short stories published in swathi weekly under title \"Maa Diguwa Godavari Kathalu\" For his contributions to the art of story telling with a native approach through his books he was bestowed with \"Sripada Puraskhaaram\" at Rajamundry on 17 April 2011.',\n",
       "   'qas': [{'question': 'మా పసలపూడి కథలు పుస్తకమును ఎవరు రచించారు?',\n",
       "     'answers': [{'text': 'Vamsy', 'answer_start': 104}],\n",
       "     'id': '-107019484199702154',\n",
       "     'lang': 'te',\n",
       "     'split': 'train'}]}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_xx['train'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:24:55.270651Z",
     "iopub.status.busy": "2022-06-14T10:24:55.270063Z",
     "iopub.status.idle": "2022-06-14T10:24:55.275200Z",
     "shell.execute_reply": "2022-06-14T10:24:55.274493Z",
     "shell.execute_reply.started": "2022-06-14T10:24:55.270621Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xorqa_answer_str(context, qas):\n",
    "    context_qa_pairs = []\n",
    "    for qa in qas:\n",
    "        question = qa['question']\n",
    "        lang = qa['lang']\n",
    "        answer = qa['answers'][0]['text']\n",
    "        answer_start = qa['answers'][0]['answer_start']\n",
    "        context_qa_pairs.append((context, question, answer, answer_start, lang))\n",
    "    return context_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:25:00.018936Z",
     "iopub.status.busy": "2022-06-14T10:25:00.018652Z",
     "iopub.status.idle": "2022-06-14T10:25:05.739609Z",
     "shell.execute_reply": "2022-06-14T10:25:05.739134Z",
     "shell.execute_reply.started": "2022-06-14T10:25:00.018906Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xorqa_xx_dataset = defaultdict(lambda: { 'train': [], 'val': [] })\n",
    "\n",
    "xorqa_sentences = []\n",
    "global_paragraph_id = 0\n",
    "global_sentence_id = 0\n",
    "\n",
    "for split_name in ['train', 'val']:\n",
    "    for i, item in enumerate(xorqa_xx[split_name]):\n",
    "\n",
    "        title = item['title']\n",
    "        paragraphs = item['paragraphs']\n",
    "\n",
    "        for j, paragraph in enumerate(paragraphs):\n",
    "\n",
    "            context = paragraph['context']\n",
    "            context_qa_pairs = get_xorqa_answer_str(context=context, qas=paragraph['qas'])\n",
    "            segmented_context = segment_sentence(context)\n",
    "            segmented_context_ids = []\n",
    "        \n",
    "            for sentence_id in range(len(segmented_context)):\n",
    "                xorqa_sentences.append((title, global_paragraph_id, global_sentence_id, segmented_context[sentence_id], split_name))\n",
    "                segmented_context_ids.append(global_sentence_id)\n",
    "                global_sentence_id += 1\n",
    "\n",
    "            for context_qa_pair in context_qa_pairs:\n",
    "                context, question, answer, answer_start, lang = context_qa_pair\n",
    "                gt_sentence, gt_sentence_idx = mine_prompt_gt((context, question, answer, answer_start))\n",
    "                gt_sentence_global_idx = segmented_context_ids[gt_sentence_idx]\n",
    "                \n",
    "                qa_item = {\n",
    "                     'question': question,\n",
    "                     'lang': lang,\n",
    "                     'context': context,\n",
    "                     'segmented_context': segment_sentence(context),\n",
    "                     'segmented_context_ids': segmented_context_ids,\n",
    "                     'answer': answer,\n",
    "                     'answer_start': answer_start,\n",
    "                     'split_name': split_name,\n",
    "                     'gt_sentence': gt_sentence,\n",
    "                     'gt_sentence_idx': gt_sentence_global_idx,\n",
    "\n",
    "                }\n",
    "                xorqa_xx_dataset[lang][split_name].append(qa_item)\n",
    "            global_paragraph_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:25:05.740973Z",
     "iopub.status.busy": "2022-06-14T10:25:05.740761Z",
     "iopub.status.idle": "2022-06-14T10:25:05.746281Z",
     "shell.execute_reply": "2022-06-14T10:25:05.745399Z",
     "shell.execute_reply.started": "2022-06-14T10:25:05.740935Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bn', 'ja', 'ko', 'ru', 'fi', ' ar', 'te', 'ar']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(xorqa_xx_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:25:05.747384Z",
     "iopub.status.busy": "2022-06-14T10:25:05.747110Z",
     "iopub.status.idle": "2022-06-14T10:25:05.752360Z",
     "shell.execute_reply": "2022-06-14T10:25:05.751323Z",
     "shell.execute_reply.started": "2022-06-14T10:25:05.747357Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xorqa_xx_dataset['ar']['val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write (English) segmented sentences into separated csv file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76113,\n",
       " ('title:WikiLeaks_parentSection:Introduction_sectionName:Introduction_sectionIndex:0',\n",
       "  0,\n",
       "  0,\n",
       "  'WikiLeaks () is an international non-profit organisation that publishes secret information, news leaks, and classified media provided by anonymous sources.'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xorqa_sentences), xorqa_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "xorqa_en_sentences_df = pd.DataFrame.from_dict(xorqa_sentences)\n",
    "xorqa_en_sentences_df.columns=['doc_title', 'paragraph_id', 'sentence_id', 'sentence', 'split_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_title</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>split_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title:WikiLeaks_parentSection:Introduction_sec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WikiLeaks () is an international non-profit or...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title:WikiLeaks_parentSection:Introduction_sec...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Its website, initiated in 2006 in Iceland by t...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>title:WikiLeaks_parentSection:Introduction_sec...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Julian Assange, an Australian Internet activis...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title:WikiLeaks_parentSection:Introduction_sec...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kristinn Hrafnsson is its editor-in-chief.</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title:World War II_parentSection:Introduction_...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The war in Europe concluded with an invasion o...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           doc_title  paragraph_id  \\\n",
       "0  title:WikiLeaks_parentSection:Introduction_sec...             0   \n",
       "1  title:WikiLeaks_parentSection:Introduction_sec...             0   \n",
       "2  title:WikiLeaks_parentSection:Introduction_sec...             0   \n",
       "3  title:WikiLeaks_parentSection:Introduction_sec...             0   \n",
       "4  title:World War II_parentSection:Introduction_...             1   \n",
       "\n",
       "   sentence_id                                           sentence split_name  \n",
       "0            0  WikiLeaks () is an international non-profit or...      train  \n",
       "1            1  Its website, initiated in 2006 in Iceland by t...      train  \n",
       "2            2  Julian Assange, an Australian Internet activis...      train  \n",
       "3            3         Kristinn Hrafnsson is its editor-in-chief.      train  \n",
       "4            4  The war in Europe concluded with an invasion o...      train  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_en_sentences_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_title</th>\n",
       "      <th>paragraph_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>split_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76108</th>\n",
       "      <td>title:Gamergate controversy_parentSection:Hist...</td>\n",
       "      <td>17110</td>\n",
       "      <td>76108</td>\n",
       "      <td>In mid-October Brianna Wu, another independent...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76109</th>\n",
       "      <td>title:Gamergate controversy_parentSection:Hist...</td>\n",
       "      <td>17110</td>\n",
       "      <td>76109</td>\n",
       "      <td>Wu then became the target of rape and death th...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76110</th>\n",
       "      <td>title:Gamergate controversy_parentSection:Hist...</td>\n",
       "      <td>17110</td>\n",
       "      <td>76110</td>\n",
       "      <td>After contacting police, Wu fled her home with...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76111</th>\n",
       "      <td>title:Gamergate controversy_parentSection:Hist...</td>\n",
       "      <td>17110</td>\n",
       "      <td>76111</td>\n",
       "      <td>Wu announced an reward for information leading...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76112</th>\n",
       "      <td>title:Gamergate controversy_parentSection:Hist...</td>\n",
       "      <td>17110</td>\n",
       "      <td>76112</td>\n",
       "      <td>As of April 2016, Wu was still receiving threa...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               doc_title  paragraph_id  \\\n",
       "76108  title:Gamergate controversy_parentSection:Hist...         17110   \n",
       "76109  title:Gamergate controversy_parentSection:Hist...         17110   \n",
       "76110  title:Gamergate controversy_parentSection:Hist...         17110   \n",
       "76111  title:Gamergate controversy_parentSection:Hist...         17110   \n",
       "76112  title:Gamergate controversy_parentSection:Hist...         17110   \n",
       "\n",
       "       sentence_id                                           sentence  \\\n",
       "76108        76108  In mid-October Brianna Wu, another independent...   \n",
       "76109        76109  Wu then became the target of rape and death th...   \n",
       "76110        76110  After contacting police, Wu fled her home with...   \n",
       "76111        76111  Wu announced an reward for information leading...   \n",
       "76112        76112  As of April 2016, Wu was still receiving threa...   \n",
       "\n",
       "      split_name  \n",
       "76108        val  \n",
       "76109        val  \n",
       "76110        val  \n",
       "76111        val  \n",
       "76112        val  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_en_sentences_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "xorqa_en_sentences_df.to_csv('./question-sentences-pairs/xorqa/xorqa_sentence-en.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write (All languages) question-sentence pairs into separated csv file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['bn', 'ja', 'ko', 'ru', 'fi', ' ar', 'te', 'ar', 'question_lang']),\n",
       " dict_keys(['train', 'val']))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_xx_dataset.keys(), xorqa_xx_dataset['bn'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'উইকিলিকস কত সালে সর্বপ্রথম ইন্টারনেটে প্রথম তথ্য প্রদর্শন করে ?',\n",
       " 'lang': 'bn',\n",
       " 'context': 'WikiLeaks () is an international non-profit organisation that publishes secret information, news leaks, and classified media provided by anonymous sources. Its website, initiated in 2006 in Iceland by the organisation Sunshine Press, claims a database of 10 million documents in 10 years since its launch. Julian Assange, an Australian Internet activist, is generally described as its founder and director. Kristinn Hrafnsson is its editor-in-chief.',\n",
       " 'segmented_context': ['WikiLeaks () is an international non-profit organisation that publishes secret information, news leaks, and classified media provided by anonymous sources.',\n",
       "  'Its website, initiated in 2006 in Iceland by the organisation Sunshine Press, claims a database of 10 million documents in 10 years since its launch.',\n",
       "  'Julian Assange, an Australian Internet activist, is generally described as its founder and director.',\n",
       "  'Kristinn Hrafnsson is its editor-in-chief.'],\n",
       " 'answer': '2006',\n",
       " 'answer_start': 182,\n",
       " 'gt_sentence': 'Its website, initiated in 2006 in Iceland by the organisation Sunshine Press, claims a database of 10 million documents in 10 years since its launch.',\n",
       " 'gt_sentence_idx': 1}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_xx_dataset['bn']['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question_lang in list(xorqa_xx_dataset.keys()):\n",
    "    \n",
    "    for split_name in list(xorqa_xx_dataset[question_lang].keys()):\n",
    "\n",
    "        if len(xorqa_xx_dataset[question_lang][split_name]) > 0:\n",
    "            xorqa_question_sentence_pairs_df = pd.DataFrame.from_dict(list(map(lambda x: (x['question'], x['gt_sentence_idx']), xorqa_xx_dataset[question_lang][split_name])))\n",
    "            xorqa_question_sentence_pairs_df.columns = ['question' , 'gt_sentence_idx']\n",
    "\n",
    "            xorqa_question_sentence_pairs_df.to_csv(f'./question-sentences-pairs/xorqa/xorqa-{split_name}_question-{question_lang}_sentence-en.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute question-sentence similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Load mUSE_small (v3) model (as a baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:25:42.613822Z",
     "iopub.status.busy": "2022-06-14T09:25:42.613593Z",
     "iopub.status.idle": "2022-06-14T09:32:56.562260Z",
     "shell.execute_reply": "2022-06-14T09:32:56.561136Z",
     "shell.execute_reply.started": "2022-06-14T09:25:42.613798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "muse_small_v3_model = load_model('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Load teacher models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-14T09:32:56.562723Z",
     "iopub.status.idle": "2022-06-14T09:32:56.562967Z",
     "shell.execute_reply": "2022-06-14T09:32:56.562842Z",
     "shell.execute_reply.started": "2022-06-14T09:32:56.562829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "XQUAD_TEACHER_DIR = '../../../../CL-ReLKT_store/models/XQUAD/teacher_model/'\n",
    "MLQA_TEACHER_DIR = '../../../../CL-ReLKT_store/models/MLQA/teacher_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xquad_teacher_model = load_model(XQUAD_TEACHER_DIR)\n",
    "mlqa_teacher_model = load_model(MLQA_TEACHER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Load student models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XQUAD_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XQUAD/student_best_supported_languages/'\n",
    "XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XQUAD/student_best_unsupported_languages/'\n",
    "\n",
    "XORQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XORQA/student_best_supported_languages/'\n",
    "XORQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XORQA/student_best_unsupported_languages/'\n",
    "\n",
    "MLQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/MLQA/student_best_supported_languages/'\n",
    "MLQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/MLQA/student_best_unsupported_languages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xquad_student_supported_langs_model = load_model(XQUAD_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "xorqa_student_supported_langs_model = load_model(XORQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "mlqa_student_supported_langs_model = load_model(MLQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "\n",
    "xquad_student_unsupported_langs_model = load_model(XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "xorqa_student_unsupported_langs_model = load_model(XORQA_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "mlqa_student_unsupported_langs_model = load_model(MLQA_STUDENT_UNSUPPORTED_LANGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAPPING = {\n",
    "  # mUSE_small\n",
    "  'model-muse_small_v3': muse_small_v3_model,\n",
    "  # teacher    \n",
    "  'model-xquad_teacher': xquad_teacher_model,\n",
    "  'model-mlqa_teacher': mlqa_teacher_model,\n",
    "  # student\n",
    "  'model-xquad_student_supported_langs': xquad_student_supported_langs_model,\n",
    "  'model-xorqa_student_supported_langs': xorqa_student_supported_langs_model,\n",
    "  'model-mlqa_student_supported_langs': mlqa_student_supported_langs_model,\n",
    "  'model-xquad_student_unsupported_langs': xquad_student_unsupported_langs_model,\n",
    "  'model-xorqa_student_unsupported_langs': xorqa_student_unsupported_langs_model,\n",
    "  'model-mlqa_student_unsupported_langs': mlqa_student_unsupported_langs_model,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:25:13.125532Z",
     "iopub.status.busy": "2022-06-14T10:25:13.125261Z",
     "iopub.status.idle": "2022-06-14T10:25:13.131586Z",
     "shell.execute_reply": "2022-06-14T10:25:13.130744Z",
     "shell.execute_reply.started": "2022-06-14T10:25:13.125504Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dataset-xorqa_bn_train', 'dataset-xorqa_bn_val', 'dataset-xorqa_ja_train', 'dataset-xorqa_ja_val', 'dataset-xorqa_ko_train', 'dataset-xorqa_ko_val', 'dataset-xorqa_ru_train', 'dataset-xorqa_ru_val', 'dataset-xorqa_fi_train', 'dataset-xorqa_fi_val', 'dataset-xorqa_ar_train', 'dataset-xorqa_te_train', 'dataset-xorqa_te_val', 'dataset-xorqa_ar_val'])\n"
     ]
    }
   ],
   "source": [
    "DATASET_MAPPING = {}\n",
    "\n",
    "for lang in list(xorqa_xx_dataset.keys()):\n",
    "    if len(xorqa_xx_dataset[lang]['train']) != 0:\n",
    "        DATASET_MAPPING[f'dataset-xorqa_{lang.strip()}_train'] = xorqa_xx_dataset[lang]['train']\n",
    "    if len(xorqa_xx_dataset[lang]['val']) != 0:\n",
    "        DATASET_MAPPING[f'dataset-xorqa_{lang.strip()}_val'] = xorqa_xx_dataset[lang]['val']\n",
    "print(DATASET_MAPPING.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Run inference and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function `run_online_prompt_mining` iterates over question-answer-passage triplets $(q_i, a_i, p_i)$ and compute \n",
    "the cosine similarity scores between question $q_i$ and segmented setences $s^i_j \\textrm{ where } p_i = ( s^i_0, \\ldots , s^i_{|p_i| - 1} )$ , and rank each quesiton-sentence pair by similairy score. Then, it evaluate the sentence-level precision@k.  Note: There is only 1 groundtruth sentence (i.e. the sentence where the answer span is a part of). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dataset_prefix: dataset-xorqa_bn_train\n",
      "\n",
      " - model_prefix: model-muse_small_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [05:04<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4062\n",
      "\t - precision_at_k:\n",
      "{1: 0.40622473726758285,\n",
      " 2: 0.6471301535974131,\n",
      " 3: 0.7934518997574778,\n",
      " 4: 0.8811641067097817,\n",
      " 5: 0.9329021827000809,\n",
      " 6: 0.9595796281325788,\n",
      " 7: 0.97696038803557,\n",
      " 8: 0.9854486661277284,\n",
      " 9: 0.9894907033144705,\n",
      " 10: 0.9911075181891673}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [05:00<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3868\n",
      "\t - precision_at_k:\n",
      "{1: 0.3868229587712207,\n",
      " 2: 0.6329830234438156,\n",
      " 3: 0.778496362166532,\n",
      " 4: 0.8779304769603881,\n",
      " 5: 0.9240097008892482,\n",
      " 6: 0.9583670169765561,\n",
      " 7: 0.9737267582861763,\n",
      " 8: 0.9834276475343573,\n",
      " 9: 0.9878738884397736,\n",
      " 10: 0.9907033144704931}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [05:05<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4228\n",
      "\t - precision_at_k:\n",
      "{1: 0.42279708973322555,\n",
      " 2: 0.650767987065481,\n",
      " 3: 0.7922392886014551,\n",
      " 4: 0.881568310428456,\n",
      " 5: 0.9284559417946645,\n",
      " 6: 0.9595796281325788,\n",
      " 7: 0.9753435731608731,\n",
      " 8: 0.9810024252223121,\n",
      " 9: 0.9886822958771221,\n",
      " 10: 0.99232012934519}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [04:47<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3108\n",
      "\t - precision_at_k:\n",
      "{1: 0.31083265966046886,\n",
      " 2: 0.5675020210185934,\n",
      " 3: 0.7485852869846402,\n",
      " 4: 0.8536782538399353,\n",
      " 5: 0.9058205335489087,\n",
      " 6: 0.9470493128536782,\n",
      " 7: 0.9652384801940178,\n",
      " 8: 0.97696038803557,\n",
      " 9: 0.9826192400970089,\n",
      " 10: 0.9886822958771221}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xorqa_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [04:58<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3015\n",
      "\t - precision_at_k:\n",
      "{1: 0.301535974130962,\n",
      " 2: 0.5642683912691997,\n",
      " 3: 0.732821341956346,\n",
      " 4: 0.8480194017784963,\n",
      " 5: 0.9042037186742118,\n",
      " 6: 0.9405820533548909,\n",
      " 7: 0.9632174616006467,\n",
      " 8: 0.9757477768795473,\n",
      " 9: 0.9822150363783346,\n",
      " 10: 0.986661277283751}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [04:55<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.4268\n",
      "\t - precision_at_k:\n",
      "{1: 0.42683912691996767,\n",
      " 2: 0.66410670978173,\n",
      " 3: 0.8055780113177041,\n",
      " 4: 0.883589329021827,\n",
      " 5: 0.9288601455133387,\n",
      " 6: 0.9555375909458367,\n",
      " 7: 0.973322554567502,\n",
      " 8: 0.9814066289409863,\n",
      " 9: 0.9858528698464026,\n",
      " 10: 0.9894907033144705}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_student_unsupported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [04:58<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.3395\n",
      "\t - precision_at_k:\n",
      "{1: 0.3395311236863379,\n",
      " 2: 0.5905416329830234,\n",
      " 3: 0.7623282134195635,\n",
      " 4: 0.862570735650768,\n",
      " 5: 0.9211802748585287,\n",
      " 6: 0.952303961196443,\n",
      " 7: 0.9717057396928052,\n",
      " 8: 0.9814066289409863,\n",
      " 9: 0.9894907033144705,\n",
      " 10: 0.9927243330638642}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xorqa_student_unsupported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2474/2474 [04:39<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.2676\n",
      "\t - precision_at_k:\n",
      "{1: 0.2675828617623282,\n",
      " 2: 0.5161681487469685,\n",
      " 3: 0.6956345998383185,\n",
      " 4: 0.8096200485044462,\n",
      " 5: 0.8848019401778496,\n",
      " 6: 0.9268391269199676,\n",
      " 7: 0.9567502021018593,\n",
      " 8: 0.9725141471301536,\n",
      " 9: 0.9785772029102667,\n",
      " 10: 0.9830234438156831}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_student_unsupported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 1521/2474 [03:01<02:01,  7.86it/s]"
     ]
    }
   ],
   "source": [
    "results = defaultdict(lambda : defaultdict())\n",
    "\n",
    "for dataset_prefix, dataset in DATASET_MAPPING.items():\n",
    "    print(f'\\n\\ndataset_prefix: {dataset_prefix}')\n",
    "    for model_prefix, model in MODEL_MAPPING.items():\n",
    "        \n",
    "        print(f'\\n - model_prefix: {model_prefix}')\n",
    "        prefix = f'{dataset_prefix}+{model_prefix}'\n",
    "        _result = run_online_prompt_mining(dataset,\n",
    "                             prefix=f'{dataset_prefix}_{model_prefix}',\n",
    "                             model=model)\n",
    "\n",
    "\n",
    "        results[dataset_prefix][model_prefix] = _result\n",
    "        print('--'*50)\n",
    "    print('\\n')    \n",
    "    print('=='*50)\n",
    "    print('\\n')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Write result as JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results, open('./eval_results.dataset_name-xorqa.json', 'w'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert evaluation results to a pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.load(open('./eval_results.dataset_name-xorqa.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dataset-xorqa_bn_train',\n",
       "  'dataset-xorqa_bn_val',\n",
       "  'dataset-xorqa_ja_train',\n",
       "  'dataset-xorqa_ja_val',\n",
       "  'dataset-xorqa_ko_train',\n",
       "  'dataset-xorqa_ko_val',\n",
       "  'dataset-xorqa_ru_train',\n",
       "  'dataset-xorqa_ru_val',\n",
       "  'dataset-xorqa_fi_train',\n",
       "  'dataset-xorqa_fi_val',\n",
       "  'dataset-xorqa_ar_train',\n",
       "  'dataset-xorqa_te_train',\n",
       "  'dataset-xorqa_te_val',\n",
       "  'dataset-xorqa_ar_val'],\n",
       " 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(results.keys()), len(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_objs = []\n",
    "for dataset_name, result_model_group in results.items():\n",
    "    for model_name, (metric, raw_result) in result_model_group.items():\n",
    "        top1, precision_at_k = metric\n",
    "        \n",
    "        result_objs.append({\n",
    "            'dataset_name': dataset_name,\n",
    "            'model_name': model_name,\n",
    "            'precision_at_1': top1,\n",
    "            'precision_at_2': precision_at_k['2'],\n",
    "            'precision_at_3': precision_at_k['6'],\n",
    "            'precision_at_4': precision_at_k['4'],\n",
    "            'precision_at_5': precision_at_k['5'],\n",
    "            'precision_at_10': precision_at_k['10'],\n",
    "        })\n",
    "    \n",
    "df = pd.DataFrame.from_dict(result_objs)\n",
    "df.to_csv('./eval_results.dataset_name-xorqa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>precision_at_1</th>\n",
       "      <th>precision_at_2</th>\n",
       "      <th>precision_at_3</th>\n",
       "      <th>precision_at_4</th>\n",
       "      <th>precision_at_5</th>\n",
       "      <th>precision_at_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset-xorqa_bn_train</td>\n",
       "      <td>model-muse_small_v3</td>\n",
       "      <td>0.406225</td>\n",
       "      <td>0.647130</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.881164</td>\n",
       "      <td>0.932902</td>\n",
       "      <td>0.991108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset-xorqa_bn_train</td>\n",
       "      <td>model-xquad_teacher</td>\n",
       "      <td>0.386823</td>\n",
       "      <td>0.632983</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>0.877930</td>\n",
       "      <td>0.924010</td>\n",
       "      <td>0.990703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset-xorqa_bn_train</td>\n",
       "      <td>model-mlqa_teacher</td>\n",
       "      <td>0.422797</td>\n",
       "      <td>0.650768</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.881568</td>\n",
       "      <td>0.928456</td>\n",
       "      <td>0.992320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset-xorqa_bn_train</td>\n",
       "      <td>model-xquad_student_supported_langs</td>\n",
       "      <td>0.310833</td>\n",
       "      <td>0.567502</td>\n",
       "      <td>0.947049</td>\n",
       "      <td>0.853678</td>\n",
       "      <td>0.905821</td>\n",
       "      <td>0.988682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset-xorqa_bn_train</td>\n",
       "      <td>model-xorqa_student_supported_langs</td>\n",
       "      <td>0.301536</td>\n",
       "      <td>0.564268</td>\n",
       "      <td>0.940582</td>\n",
       "      <td>0.848019</td>\n",
       "      <td>0.904204</td>\n",
       "      <td>0.986661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>dataset-xorqa_ar_val</td>\n",
       "      <td>model-xorqa_student_supported_langs</td>\n",
       "      <td>0.494845</td>\n",
       "      <td>0.721649</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>0.917526</td>\n",
       "      <td>0.958763</td>\n",
       "      <td>0.995876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>dataset-xorqa_ar_val</td>\n",
       "      <td>model-mlqa_student_supported_langs</td>\n",
       "      <td>0.540206</td>\n",
       "      <td>0.748454</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>0.931959</td>\n",
       "      <td>0.967010</td>\n",
       "      <td>0.989691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>dataset-xorqa_ar_val</td>\n",
       "      <td>model-xquad_student_unsupported_langs</td>\n",
       "      <td>0.404124</td>\n",
       "      <td>0.628866</td>\n",
       "      <td>0.956701</td>\n",
       "      <td>0.880412</td>\n",
       "      <td>0.925773</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>dataset-xorqa_ar_val</td>\n",
       "      <td>model-xorqa_student_unsupported_langs</td>\n",
       "      <td>0.453608</td>\n",
       "      <td>0.717526</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>0.921649</td>\n",
       "      <td>0.962887</td>\n",
       "      <td>0.985567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>dataset-xorqa_ar_val</td>\n",
       "      <td>model-mlqa_student_unsupported_langs</td>\n",
       "      <td>0.556701</td>\n",
       "      <td>0.744330</td>\n",
       "      <td>0.979381</td>\n",
       "      <td>0.915464</td>\n",
       "      <td>0.960825</td>\n",
       "      <td>0.987629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset_name                             model_name  \\\n",
       "0    dataset-xorqa_bn_train                    model-muse_small_v3   \n",
       "1    dataset-xorqa_bn_train                    model-xquad_teacher   \n",
       "2    dataset-xorqa_bn_train                     model-mlqa_teacher   \n",
       "3    dataset-xorqa_bn_train    model-xquad_student_supported_langs   \n",
       "4    dataset-xorqa_bn_train    model-xorqa_student_supported_langs   \n",
       "..                      ...                                    ...   \n",
       "121    dataset-xorqa_ar_val    model-xorqa_student_supported_langs   \n",
       "122    dataset-xorqa_ar_val     model-mlqa_student_supported_langs   \n",
       "123    dataset-xorqa_ar_val  model-xquad_student_unsupported_langs   \n",
       "124    dataset-xorqa_ar_val  model-xorqa_student_unsupported_langs   \n",
       "125    dataset-xorqa_ar_val   model-mlqa_student_unsupported_langs   \n",
       "\n",
       "     precision_at_1  precision_at_2  precision_at_3  precision_at_4  \\\n",
       "0          0.406225        0.647130        0.959580        0.881164   \n",
       "1          0.386823        0.632983        0.958367        0.877930   \n",
       "2          0.422797        0.650768        0.959580        0.881568   \n",
       "3          0.310833        0.567502        0.947049        0.853678   \n",
       "4          0.301536        0.564268        0.940582        0.848019   \n",
       "..              ...             ...             ...             ...   \n",
       "121        0.494845        0.721649        0.975258        0.917526   \n",
       "122        0.540206        0.748454        0.975258        0.931959   \n",
       "123        0.404124        0.628866        0.956701        0.880412   \n",
       "124        0.453608        0.717526        0.975258        0.921649   \n",
       "125        0.556701        0.744330        0.979381        0.915464   \n",
       "\n",
       "     precision_at_5  precision_at_10  \n",
       "0          0.932902         0.991108  \n",
       "1          0.924010         0.990703  \n",
       "2          0.928456         0.992320  \n",
       "3          0.905821         0.988682  \n",
       "4          0.904204         0.986661  \n",
       "..              ...              ...  \n",
       "121        0.958763         0.995876  \n",
       "122        0.967010         0.989691  \n",
       "123        0.925773         1.000000  \n",
       "124        0.962887         0.985567  \n",
       "125        0.960825         0.987629  \n",
       "\n",
       "[126 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
