{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-14T09:32:56.564473Z",
     "iopub.status.idle": "2022-06-14T09:32:56.564869Z",
     "shell.execute_reply": "2022-06-14T09:32:56.564718Z",
     "shell.execute_reply.started": "2022-06-14T09:32:56.564700Z"
    },
    "tags": []
   },
   "source": [
    "## Sentence-level online prompty mining: XQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:35.027042Z",
     "iopub.status.busy": "2022-06-14T10:21:35.026818Z",
     "iopub.status.idle": "2022-06-14T10:21:35.030553Z",
     "shell.execute_reply": "2022-06-14T10:21:35.029993Z",
     "shell.execute_reply.started": "2022-06-14T10:21:35.027020Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "import os, sys\n",
    "import json\n",
    "import glob\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import jsonlines\n",
    "\n",
    "from exploring_sentence_level import (\n",
    "    load_model,\n",
    "    mine_prompt_gt,  \n",
    "    segment_sentence,\n",
    "    run_online_prompt_mining\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Download dataset\n",
    "\n",
    "```bash\n",
    "cd ../scripts\n",
    "bash ./download_xquad_v1.1.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:36.323738Z",
     "iopub.status.busy": "2022-06-14T10:21:36.323467Z",
     "iopub.status.idle": "2022-06-14T10:21:36.339393Z",
     "shell.execute_reply": "2022-06-14T10:21:36.338640Z",
     "shell.execute_reply.started": "2022-06-14T10:21:36.323705Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['data', 'version']), '1.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XQUAD_BASE_DIR = '../data/xquad/xx/'\n",
    "xquad_en = json.load(open(os.path.join(XQUAD_BASE_DIR, 'xquad.en.json'), 'r'))\n",
    "xquad_en.keys(), \\\n",
    "xquad_en['version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:36.815362Z",
     "iopub.status.busy": "2022-06-14T10:21:36.815093Z",
     "iopub.status.idle": "2022-06-14T10:21:36.819777Z",
     "shell.execute_reply": "2022-06-14T10:21:36.819181Z",
     "shell.execute_reply.started": "2022-06-14T10:21:36.815332Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_squad_answer_str(context, qas):\n",
    "    context_qa_pairs = []\n",
    "    for qa in qas:\n",
    "        question = qa['question']\n",
    "        answer = qa['answers'][0]['text']\n",
    "        answer_start = qa['answers'][0]['answer_start']\n",
    "        context_qa_pairs.append((context, question, answer, answer_start))\n",
    "    return context_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:37.516209Z",
     "iopub.status.busy": "2022-06-14T10:21:37.515969Z",
     "iopub.status.idle": "2022-06-14T10:21:37.520821Z",
     "shell.execute_reply": "2022-06-14T10:21:37.520291Z",
     "shell.execute_reply.started": "2022-06-14T10:21:37.516184Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tesla was renowned for his achievements and showmanship, eventually earning him a reputation in popular culture as an archetypal \"mad scientist\". His patents earned him a considerable amount of money, much of which was used to finance his own projects with varying degrees of success.:121,154 He lived most of his life in a series of New York hotels, through his retirement. Tesla died on 7 January 1943. His work fell into relative obscurity after his death, but in 1960 the General Conference on Weights and Measures named the SI unit of magnetic flux density the tesla in his honor. There has been a resurgence in popular interest in Tesla since the 1990s.',\n",
       " 'What year did Tesla die? ',\n",
       " '1943',\n",
       " 399)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = xquad_en['data'][3]['paragraphs'][0]\n",
    "context_qa_pairs = get_squad_answer_str(context=item['context'], qas=item['qas'])\n",
    "context_qa_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "class xquad_dataset_item:\n",
    "    question: str\n",
    "    context: str\n",
    "    segmented_context: str\n",
    "    answer: str\n",
    "    answer_start: int\n",
    "    gt_sentence: str\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:38.312632Z",
     "iopub.status.busy": "2022-06-14T10:21:38.312324Z",
     "iopub.status.idle": "2022-06-14T10:21:38.812207Z",
     "shell.execute_reply": "2022-06-14T10:21:38.811707Z",
     "shell.execute_reply.started": "2022-06-14T10:21:38.312597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................"
     ]
    }
   ],
   "source": [
    "xquad_question_counter = Counter()\n",
    "n_paragraph = len(xquad_en['data'])\n",
    "xquad_dataset=[]\n",
    "for i, item in enumerate(xquad_en['data']):\n",
    "    paragraphs = item['paragraphs']\n",
    "    print('.' ,end='')\n",
    "    for j, paragraph in enumerate(paragraphs):\n",
    "        xquad_question_counter[f'd-{i}_p-{j}'] = len(paragraph['qas'])\n",
    "        \n",
    "        context = paragraph['context']\n",
    "        context_qa_pairs = get_squad_answer_str(context=context, qas=paragraph['qas'])\n",
    "\n",
    "        for context_qa_pair in context_qa_pairs:\n",
    "            context, question, answer, answer_start = context_qa_pair\n",
    "            gt_sentence = mine_prompt_gt(context_qa_pair)\n",
    "            qa_item = {\n",
    "                 'question': question,\n",
    "                    'context': context,\n",
    "                    'segmented_context': segment_sentence(context),\n",
    "                    'answer': answer,\n",
    "                    'answer_start': answer_start,\n",
    "                    'gt_sentence': gt_sentence,\n",
    "            }\n",
    "            xquad_dataset.append(qa_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:38.964706Z",
     "iopub.status.busy": "2022-06-14T10:21:38.964435Z",
     "iopub.status.idle": "2022-06-14T10:21:38.969199Z",
     "shell.execute_reply": "2022-06-14T10:21:38.968682Z",
     "shell.execute_reply.started": "2022-06-14T10:21:38.964675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1190"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sum(xquad_question_counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:39.412395Z",
     "iopub.status.busy": "2022-06-14T10:21:39.412092Z",
     "iopub.status.idle": "2022-06-14T10:21:39.417267Z",
     "shell.execute_reply": "2022-06-14T10:21:39.416717Z",
     "shell.execute_reply.started": "2022-06-14T10:21:39.412360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How many points did the Panthers defense surrender?',\n",
       " 'context': \"The Panthers defense gave up just 308 points, ranking sixth in the league, while also leading the NFL in interceptions with 24 and boasting four Pro Bowl selections. Pro Bowl defensive tackle Kawann Short led the team in sacks with 11, while also forcing three fumbles and recovering two. Fellow lineman Mario Addison added 6½ sacks. The Panthers line also featured veteran defensive end Jared Allen, a 5-time pro bowler who was the NFL's active career sack leader with 136, along with defensive end Kony Ealy, who had 5 sacks in just 9 starts. Behind them, two of the Panthers three starting linebackers were also selected to play in the Pro Bowl: Thomas Davis and Luke Kuechly. Davis compiled 5½ sacks, four forced fumbles, and four interceptions, while Kuechly led the team in tackles (118) forced two fumbles, and intercepted four passes of his own. Carolina's secondary featured Pro Bowl safety Kurt Coleman, who led the team with a career high seven interceptions, while also racking up 88 tackles and Pro Bowl cornerback Josh Norman, who developed into a shutdown corner during the season and had four interceptions, two of which were returned for touchdowns.\",\n",
       " 'segmented_context': ['The Panthers defense gave up just 308 points, ranking sixth in the league, while also leading the NFL in interceptions with 24 and boasting four Pro Bowl selections.',\n",
       "  'Pro Bowl defensive tackle Kawann Short led the team in sacks with 11, while also forcing three fumbles and recovering two.',\n",
       "  'Fellow lineman Mario Addison added 6½ sacks.',\n",
       "  \"The Panthers line also featured veteran defensive end Jared Allen, a 5-time pro bowler who was the NFL's active career sack leader with 136, along with defensive end Kony Ealy, who had 5 sacks in just 9 starts.\",\n",
       "  'Behind them, two of the Panthers three starting linebackers were also selected to play in the Pro Bowl: Thomas Davis and Luke Kuechly.',\n",
       "  'Davis compiled 5½ sacks, four forced fumbles, and four interceptions, while Kuechly led the team in tackles (118) forced two fumbles, and intercepted four passes of his own.',\n",
       "  \"Carolina's secondary featured Pro Bowl safety Kurt Coleman, who led the team with a career high seven interceptions, while also racking up 88 tackles and Pro Bowl cornerback Josh Norman, who developed into a shutdown corner during the season and had four interceptions, two of which were returned for touchdowns.\"],\n",
       " 'answer': '308',\n",
       " 'answer_start': 34,\n",
       " 'gt_sentence': 'The Panthers defense gave up just 308 points, ranking sixth in the league, while also leading the NFL in interceptions with 24 and boasting four Pro Bowl selections.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xquad_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute question-sentence similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Load mUSE_small (v3) model (as a baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T09:25:42.613822Z",
     "iopub.status.busy": "2022-06-14T09:25:42.613593Z",
     "iopub.status.idle": "2022-06-14T09:32:56.562260Z",
     "shell.execute_reply": "2022-06-14T09:32:56.561136Z",
     "shell.execute_reply.started": "2022-06-14T09:25:42.613798Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "muse_small_v3_model = load_model('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Load teacher models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-06-14T09:32:56.562723Z",
     "iopub.status.idle": "2022-06-14T09:32:56.562967Z",
     "shell.execute_reply": "2022-06-14T09:32:56.562842Z",
     "shell.execute_reply.started": "2022-06-14T09:32:56.562829Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "XQUAD_TEACHER_DIR = '../../../../CL-ReLKT_store/models/XQUAD/teacher_model/'\n",
    "MLQA_TEACHER_DIR = '../../../../CL-ReLKT_store/models/MLQA/teacher_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xquad_teacher_model = load_model(XQUAD_TEACHER_DIR)\n",
    "mlqa_teacher_model = load_model(MLQA_TEACHER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Load student models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XQUAD_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XQUAD/student_best_supported_languages/'\n",
    "XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XQUAD/student_best_unsupported_languages/'\n",
    "\n",
    "XORQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XORQA/student_best_supported_languages/'\n",
    "XORQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/XORQA/student_best_unsupported_languages/'\n",
    "\n",
    "MLQA_STUDENT_SUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/MLQA/student_best_supported_languages/'\n",
    "MLQA_STUDENT_UNSUPPORTED_LANGS_DIR = '../../../../CL-ReLKT_store/models/MLQA/student_best_unsupported_languages/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xquad_student_supported_langs_model = load_model(XQUAD_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "xorqa_student_supported_langs_model = load_model(XORQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "mlqa_student_supported_langs_model = load_model(MLQA_STUDENT_SUPPORTED_LANGS_DIR)\n",
    "\n",
    "xquad_student_unsupported_langs_model = load_model(XQUAD_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "xorqa_student_unsupported_langs_model = load_model(XORQA_STUDENT_UNSUPPORTED_LANGS_DIR)\n",
    "mlqa_student_unsupported_langs_model = load_model(MLQA_STUDENT_UNSUPPORTED_LANGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAPPING = {\n",
    "  # mUSE_small\n",
    "  'model-muse_small_v3': muse_small_v3_model,\n",
    "  # teacher    \n",
    "  'model-xquad_teacher': xquad_teacher_model,\n",
    "  'model-mlqa_teacher': mlqa_teacher_model,\n",
    "  # student\n",
    "  'model-xquad_student_supported_langs': xquad_student_supported_langs_model,\n",
    "  'model-xorqa_student_supported_langs': xorqa_student_supported_langs_model,\n",
    "  'model-mlqa_student_supported_langs': mlqa_student_supported_langs_model,\n",
    "  'model-xquad_student_unsupported_langs': xquad_student_unsupported_langs_model,\n",
    "  'model-xorqa_student_unsupported_langs': xorqa_student_unsupported_langs_model,\n",
    "  'model-mlqa_student_unsupported_langs': mlqa_student_unsupported_langs_model,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-14T10:21:44.634952Z",
     "iopub.status.busy": "2022-06-14T10:21:44.634667Z",
     "iopub.status.idle": "2022-06-14T10:21:44.640306Z",
     "shell.execute_reply": "2022-06-14T10:21:44.638995Z",
     "shell.execute_reply.started": "2022-06-14T10:21:44.634919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset-xquad_en_train'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "DATASET_MAPPING = {\n",
    "    'dataset-xquad_en_train': xquad_dataset,\n",
    "}\n",
    "DATASET_MAPPING.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Run inference and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function `run_online_prompt_mining` iterates over question-answer-passage triplets $(q_i, a_i, p_i)$ and compute \n",
    "the cosine similarity scores between question $q_i$ and segmented setences $s^i_j \\textrm{ where } p_i = ( s^i_0, \\ldots , s^i_{|p_i| - 1} )$ , and rank each quesiton-sentence pair by similairy score. Then, it evaluate the sentence-level precision@k.  Note: There is only 1 groundtruth sentence (i.e. the sentence where the answer span is a part of). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "dataset_prefix: dataset-xquad_en_train\n",
      "\n",
      " - model_prefix: model-muse_small_v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [02:31<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7118\n",
      "\t - precision_at_k:\n",
      "{1: 0.711764705882353,\n",
      " 2: 0.8739495798319328,\n",
      " 3: 0.9436974789915966,\n",
      " 4: 0.9722689075630252,\n",
      " 5: 0.9865546218487395,\n",
      " 6: 0.9907563025210084,\n",
      " 7: 0.9957983193277311,\n",
      " 8: 0.9974789915966387,\n",
      " 9: 0.9974789915966387,\n",
      " 10: 0.9974789915966387}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [02:28<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7160\n",
      "\t - precision_at_k:\n",
      "{1: 0.7159663865546219,\n",
      " 2: 0.8789915966386554,\n",
      " 3: 0.9352941176470588,\n",
      " 4: 0.9714285714285714,\n",
      " 5: 0.9882352941176471,\n",
      " 6: 0.9932773109243698,\n",
      " 7: 0.9957983193277311,\n",
      " 8: 0.9966386554621849,\n",
      " 9: 0.9974789915966387,\n",
      " 10: 0.9974789915966387}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-mlqa_teacher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1190/1190 [02:33<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tEvaluation result:\n",
      "\t - Accuracy: 0.7319\n",
      "\t - precision_at_k:\n",
      "{1: 0.7319327731092437,\n",
      " 2: 0.8798319327731092,\n",
      " 3: 0.9411764705882353,\n",
      " 4: 0.9773109243697479,\n",
      " 5: 0.9907563025210084,\n",
      " 6: 0.9932773109243698,\n",
      " 7: 0.9957983193277311,\n",
      " 8: 0.9966386554621849,\n",
      " 9: 0.9983193277310924,\n",
      " 10: 0.9983193277310924}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      " - model_prefix: model-xquad_student_supported_langs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1024/1190 [02:10<00:20,  8.27it/s]"
     ]
    }
   ],
   "source": [
    "results = defaultdict(lambda : defaultdict())\n",
    "\n",
    "for dataset_prefix, dataset in DATASET_MAPPING.items():\n",
    "    print(f'\\n\\ndataset_prefix: {dataset_prefix}')\n",
    "    for model_prefix, model in MODEL_MAPPING.items():\n",
    "        \n",
    "        print(f'\\n - model_prefix: {model_prefix}')\n",
    "        prefix = f'{dataset_prefix}+{model_prefix}'\n",
    "        _result = run_online_prompt_mining(dataset,\n",
    "                             prefix=f'{dataset_prefix}_{model_prefix}',\n",
    "                             model=model)\n",
    "\n",
    "\n",
    "        results[dataset_prefix][model_prefix] = _result\n",
    "        print('--'*50)\n",
    "    print('\\n')    \n",
    "    print('=='*50)\n",
    "    print('\\n')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Write result as JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(results, open('./eval_results.dataset_name-xquad.json', 'w'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convert evaluation results to a pandas.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = json.load(open('./eval_results.dataset_name-xquad.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dataset-xquad_en_train'], 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(results.keys()), len(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_objs = []\n",
    "for dataset_name, result_model_group in results.items():\n",
    "    for model_name, (metric, raw_result) in result_model_group.items():\n",
    "        top1, precision_at_k = metric\n",
    "        \n",
    "        result_objs.append({\n",
    "            'dataset_name': dataset_name,\n",
    "            'model_name': model_name,\n",
    "            'precision_at_1': top1,\n",
    "            'precision_at_2': precision_at_k['2'],\n",
    "            'precision_at_3': precision_at_k['6'],\n",
    "            'precision_at_4': precision_at_k['4'],\n",
    "            'precision_at_5': precision_at_k['5'],\n",
    "            'precision_at_10': precision_at_k['10'],\n",
    "        })\n",
    "    \n",
    "df = pd.DataFrame.from_dict(result_objs)\n",
    "df.to_csv('./eval_results.dataset_name-xquad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>precision_at_1</th>\n",
       "      <th>precision_at_2</th>\n",
       "      <th>precision_at_3</th>\n",
       "      <th>precision_at_4</th>\n",
       "      <th>precision_at_5</th>\n",
       "      <th>precision_at_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-muse_small_v3</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>0.873950</td>\n",
       "      <td>0.990756</td>\n",
       "      <td>0.972269</td>\n",
       "      <td>0.986555</td>\n",
       "      <td>0.997479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-xquad_teacher</td>\n",
       "      <td>0.715966</td>\n",
       "      <td>0.878992</td>\n",
       "      <td>0.993277</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.997479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-mlqa_teacher</td>\n",
       "      <td>0.731933</td>\n",
       "      <td>0.879832</td>\n",
       "      <td>0.993277</td>\n",
       "      <td>0.977311</td>\n",
       "      <td>0.990756</td>\n",
       "      <td>0.998319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-xquad_student_supported_langs</td>\n",
       "      <td>0.468067</td>\n",
       "      <td>0.668908</td>\n",
       "      <td>0.981513</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>0.945378</td>\n",
       "      <td>0.998319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-xorqa_student_supported_langs</td>\n",
       "      <td>0.712605</td>\n",
       "      <td>0.851261</td>\n",
       "      <td>0.990756</td>\n",
       "      <td>0.968067</td>\n",
       "      <td>0.986555</td>\n",
       "      <td>0.997479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-mlqa_student_supported_langs</td>\n",
       "      <td>0.737815</td>\n",
       "      <td>0.884034</td>\n",
       "      <td>0.993277</td>\n",
       "      <td>0.978992</td>\n",
       "      <td>0.989076</td>\n",
       "      <td>0.997479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-xquad_student_unsupported_langs</td>\n",
       "      <td>0.401681</td>\n",
       "      <td>0.620168</td>\n",
       "      <td>0.968908</td>\n",
       "      <td>0.883193</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.993277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-xorqa_student_unsupported_langs</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.840336</td>\n",
       "      <td>0.993277</td>\n",
       "      <td>0.962185</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.997479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset-xquad_en_train</td>\n",
       "      <td>model-mlqa_student_unsupported_langs</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.993277</td>\n",
       "      <td>0.975630</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.998319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset_name                             model_name  \\\n",
       "0  dataset-xquad_en_train                    model-muse_small_v3   \n",
       "1  dataset-xquad_en_train                    model-xquad_teacher   \n",
       "2  dataset-xquad_en_train                     model-mlqa_teacher   \n",
       "3  dataset-xquad_en_train    model-xquad_student_supported_langs   \n",
       "4  dataset-xquad_en_train    model-xorqa_student_supported_langs   \n",
       "5  dataset-xquad_en_train     model-mlqa_student_supported_langs   \n",
       "6  dataset-xquad_en_train  model-xquad_student_unsupported_langs   \n",
       "7  dataset-xquad_en_train  model-xorqa_student_unsupported_langs   \n",
       "8  dataset-xquad_en_train   model-mlqa_student_unsupported_langs   \n",
       "\n",
       "   precision_at_1  precision_at_2  precision_at_3  precision_at_4  \\\n",
       "0        0.711765        0.873950        0.990756        0.972269   \n",
       "1        0.715966        0.878992        0.993277        0.971429   \n",
       "2        0.731933        0.879832        0.993277        0.977311   \n",
       "3        0.468067        0.668908        0.981513        0.899160   \n",
       "4        0.712605        0.851261        0.990756        0.968067   \n",
       "5        0.737815        0.884034        0.993277        0.978992   \n",
       "6        0.401681        0.620168        0.968908        0.883193   \n",
       "7        0.689076        0.840336        0.993277        0.962185   \n",
       "8        0.717647        0.871429        0.993277        0.975630   \n",
       "\n",
       "   precision_at_5  precision_at_10  \n",
       "0        0.986555         0.997479  \n",
       "1        0.988235         0.997479  \n",
       "2        0.990756         0.998319  \n",
       "3        0.945378         0.998319  \n",
       "4        0.986555         0.997479  \n",
       "5        0.989076         0.997479  \n",
       "6        0.941176         0.993277  \n",
       "7        0.982353         0.997479  \n",
       "8        0.988235         0.998319  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
