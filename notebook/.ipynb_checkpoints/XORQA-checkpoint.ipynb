{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config) \n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tensorflow.keras.layers import Layer,Input,Dense,Lambda\n",
    "from tensorflow.keras import Model\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from glob import glob\n",
    "import setting as set_fnc\n",
    "import copy as cp\n",
    "\n",
    "use_enc_large = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "use_enc_small = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "q_lan = ['ru','ko','fi','ja']\n",
    "corpus = 'XORQA'\n",
    "\n",
    "df_question = {}\n",
    "df_paragraph = {}\n",
    "df_doc = pd.read_csv(f'../datasets/{corpus}/{mode}/{corpus.lower()}_doc_en-ru.csv')\n",
    "for lan in q_lan:\n",
    "    df_question.update({\n",
    "        f'en-{lan}':pd.read_csv(f'../datasets/{corpus}/{mode}/{corpus.lower()}_question_en-{lan}_mbart.csv').drop_duplicates(subset=['question'])\n",
    "    })  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mUSE Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:00<00:00, 562.39it/s]\n",
      "  5%|▌         | 26/474 [00:00<00:01, 257.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE-ru\n",
      "Traninng Score P@1: 0.582\n",
      "Traninng Score P@5: 0.797\n",
      "Traninng Score P@10: 0.854\n",
      "Mrr score:0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 474/474 [00:00<00:00, 576.86it/s]\n",
      "  8%|▊         | 31/371 [00:00<00:01, 306.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE-ko\n",
      "Traninng Score P@1: 0.477\n",
      "Traninng Score P@5: 0.707\n",
      "Traninng Score P@10: 0.783\n",
      "Mrr score:0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371/371 [00:00<00:00, 524.14it/s]\n",
      " 14%|█▍        | 55/386 [00:00<00:00, 542.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE-fi\n",
      "Traninng Score P@1: 0.248\n",
      "Traninng Score P@5: 0.353\n",
      "Traninng Score P@10: 0.394\n",
      "Mrr score:0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 386/386 [00:00<00:00, 609.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE-ja\n",
      "Traninng Score P@1: 0.495\n",
      "Traninng Score P@5: 0.720\n",
      "Traninng Score P@10: 0.788\n",
      "Mrr score:0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mUSE_model = hub.load(f'../models/{corpus}/finetuned_USE_XORQA_train_en-ru_ko_ja_top0-0_q-d-distillation_1000MSE_0.1MSEq_1.0MSEd_0.1MSEqd_0.001LR_teacher_best_teacher_batchsize_16_acc_metric_3term')\n",
    "doc_context_id = df_doc['doc_id'].to_list()    \n",
    "doc_context_encoded = mUSE_model(df_doc['doc'].to_list()).numpy()\n",
    "for lan in q_lan:\n",
    "    question_id = df_question[f'en-{lan}']['doc_id'].to_list()\n",
    "    questions = mUSE_model(df_question[f'en-{lan}']['question'].to_list()).numpy()\n",
    "    \n",
    "    top_1,top_5,top_10,mrr = set_fnc.evaluate(question_id,questions,doc_context_id,doc_context_encoded)\n",
    "\n",
    "    print(f'USE-{lan}')\n",
    "    precision = top_1 / len(questions)\n",
    "    print(f\"Traninng Score P@1: {precision:.3f}\")\n",
    "    precision = top_5 / len(questions)\n",
    "    print(f\"Traninng Score P@5: {precision:.3f}\")\n",
    "    precision = top_10 / len(questions)\n",
    "    print(f\"Traninng Score P@10: {precision:.3f}\")\n",
    "    print(f\"Mrr score:{mrr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence-Transformer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_model = SentenceTransformer('XXXXXXX')\n",
    "for lan in q_lan[:]:\n",
    "    set_fnc.sent_bert_encode(ST_model,'ST_model',lan,df_doc,df_question)\n",
    "    print('*'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
