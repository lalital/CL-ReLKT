{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config) \n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tensorflow.keras.layers import Layer,Input,Dense,Lambda\n",
    "from tensorflow.keras import Model\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from glob import glob\n",
    "import setting as set_fnc\n",
    "import copy as cp\n",
    "\n",
    "use_enc_large = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "use_enc_small = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "q_lan = ['ar','de','es','hi','vi','zh']\n",
    "d_lan = ['en']\n",
    "corpus = 'MLQA'\n",
    "\n",
    "df_question = {}\n",
    "df_paragraph = {}\n",
    "df_doc = {}\n",
    "for lan in q_lan:\n",
    "    df_question.update({\n",
    "        f'en-{lan}':pd.read_csv(f'../datasets/{corpus}/{mode}/{corpus.lower()}_question_en-{lan}.csv')\n",
    "    }) \n",
    "    df_doc.update({\n",
    "        f'en-{lan}':pd.read_csv(f'../datasets/{corpus}/{mode}/{corpus.lower()}_doc_en-{lan}.csv')\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mUSE Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [00:00<00:00, 2834.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distil comp-ar\n",
      "Traninng Score P@1: 0.485\n",
      "Traninng Score P@5: 0.689\n",
      "Traninng Score P@10: 0.764\n",
      "Mrr score:0.570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:00<00:00, 4276.71it/s]\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distil comp-de\n",
      "Traninng Score P@1: 0.648\n",
      "Traninng Score P@5: 0.824\n",
      "Traninng Score P@10: 0.877\n",
      "Mrr score:0.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 3349.57it/s]\n",
      "  0%|          | 0/507 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distil comp-es\n",
      "Traninng Score P@1: 0.628\n",
      "Traninng Score P@5: 0.810\n",
      "Traninng Score P@10: 0.856\n",
      "Mrr score:0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507/507 [00:00<00:00, 2770.57it/s]\n",
      "  0%|          | 0/511 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distil comp-hi\n",
      "Traninng Score P@1: 0.020\n",
      "Traninng Score P@5: 0.047\n",
      "Traninng Score P@10: 0.091\n",
      "Mrr score:0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 511/511 [00:00<00:00, 5332.41it/s]\n",
      "  0%|          | 0/504 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distil comp-vi\n",
      "Traninng Score P@1: 0.280\n",
      "Traninng Score P@5: 0.364\n",
      "Traninng Score P@10: 0.425\n",
      "Mrr score:0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 504/504 [00:00<00:00, 3191.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distil comp-zh\n",
      "Traninng Score P@1: 0.579\n",
      "Traninng Score P@5: 0.778\n",
      "Traninng Score P@10: 0.847\n",
      "Mrr score:0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mUSE_model = hub.load(f'../models/{corpus}/finetuned_USE_MLQA_train_en-ar_de_es_zh_top0-0_q-d-distillation_1000MSE_0.01MSEq_1.0MSEd_0.0001MSEqd_0.0005LR_teacher_best_teacher_batchsize_16_acc_metric_3term')\n",
    "for lan in q_lan[:]:\n",
    "    doc_context_id = df_doc[f'en-{lan}']['doc_id'].to_list()\n",
    "    doc_context_encoded = mUSE_model(df_doc[f'en-{lan}']['doc'].to_list()).numpy()\n",
    "    \n",
    "    question_id = df_question[f'en-{lan}']['doc_id'].to_list()\n",
    "    questions = mUSE_model(df_question[f'en-{lan}']['question'].to_list()).numpy()\n",
    "    \n",
    "    top_1,top_5,top_10,mrr = set_fnc.evaluate(question_id,questions,doc_context_id,doc_context_encoded)\n",
    "\n",
    "    print(f'distil comp-{lan}')\n",
    "    precision = top_1 / len(questions)\n",
    "    print(f\"Traninng Score P@1: {precision:.3f}\")\n",
    "    precision = top_5 / len(questions)\n",
    "    print(f\"Traninng Score P@5: {precision:.3f}\")\n",
    "    precision = top_10 / len(questions)\n",
    "    print(f\"Traninng Score P@10: {precision:.3f}\")\n",
    "    print(f\"Mrr score:{mrr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence-Transformer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_model = SentenceTransformer('XXXXX')\n",
    "for lan in q_lan[:]:\n",
    "    set_fnc.sent_bert_encode(ST_model,'ST_model',lan,df_doc[f'en-{lan}'],df_question)\n",
    "    print('*'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
