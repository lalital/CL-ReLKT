{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.Session(config=config) \n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tensorflow.keras.layers import Layer,Input,Dense,Lambda\n",
    "from tensorflow.keras import Model\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from glob import glob\n",
    "import setting as set_fnc\n",
    "import copy as cp\n",
    "\n",
    "use_enc_large = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
    "use_enc_small = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'test'\n",
    "q_lan = ['ar','de','es','ru','th','zh','tr','ro','el','hi','vi']\n",
    "corpus = 'XQUAD'\n",
    "\n",
    "df_question = {}\n",
    "df_paragraph = {}\n",
    "df_doc = pd.read_csv(f'../datasets/{corpus}/{mode}/{corpus.lower()}_doc_en-en.csv')\n",
    "for lan in q_lan:\n",
    "    df_question.update({\n",
    "        f'en-{lan}':pd.read_csv(f'../datasets/{corpus}/{mode}/{corpus.lower()}_question_en-{lan}.csv')\n",
    "    })  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mUSE Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:00<00:00, 17232.20it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 12288.05it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 10325.24it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 11275.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE-ar\n",
      "Traninng Score P@1: 0.794\n",
      "Traninng Score P@5: 0.899\n",
      "Traninng Score P@10: 0.933\n",
      "Mrr score:0.843\n",
      "USE-de\n",
      "Traninng Score P@1: 0.832\n",
      "Traninng Score P@5: 0.912\n",
      "Traninng Score P@10: 0.954\n",
      "Mrr score:0.871\n",
      "USE-es\n",
      "Traninng Score P@1: 0.840\n",
      "Traninng Score P@5: 0.941\n",
      "Traninng Score P@10: 0.962\n",
      "Mrr score:0.882\n",
      "USE-ru\n",
      "Traninng Score P@1: 0.832\n",
      "Traninng Score P@5: 0.933\n",
      "Traninng Score P@10: 0.958\n",
      "Mrr score:0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:00<00:00, 11719.10it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 11038.50it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 10966.46it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 11275.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE-th\n",
      "Traninng Score P@1: 0.857\n",
      "Traninng Score P@5: 0.945\n",
      "Traninng Score P@10: 0.983\n",
      "Mrr score:0.896\n",
      "USE-zh\n",
      "Traninng Score P@1: 0.824\n",
      "Traninng Score P@5: 0.929\n",
      "Traninng Score P@10: 0.945\n",
      "Mrr score:0.866\n",
      "USE-tr\n",
      "Traninng Score P@1: 0.803\n",
      "Traninng Score P@5: 0.912\n",
      "Traninng Score P@10: 0.954\n",
      "Mrr score:0.860\n",
      "USE-ro\n",
      "Traninng Score P@1: 0.525\n",
      "Traninng Score P@5: 0.693\n",
      "Traninng Score P@10: 0.794\n",
      "Mrr score:0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 238/238 [00:00<00:00, 11926.46it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 9324.59it/s]\n",
      "100%|██████████| 238/238 [00:00<00:00, 10077.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE-el\n",
      "Traninng Score P@1: 0.101\n",
      "Traninng Score P@5: 0.202\n",
      "Traninng Score P@10: 0.319\n",
      "Mrr score:0.150\n",
      "USE-hi\n",
      "Traninng Score P@1: 0.063\n",
      "Traninng Score P@5: 0.168\n",
      "Traninng Score P@10: 0.303\n",
      "Mrr score:0.111\n",
      "USE-vi\n",
      "Traninng Score P@1: 0.298\n",
      "Traninng Score P@5: 0.420\n",
      "Traninng Score P@10: 0.525\n",
      "Mrr score:0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mUSE_model = hub.load(f'../models/{corpus}/finetuned_USE_XQUAD_train_en-ar_de_es_ru_th_zh_tr_top0-0_q-d-distillation_1000MSE_0.001MSEq_1.0MSEd_0.01MSEqd_0.001LR_teacher_best_teacher_batchsize_16_acc_metric_3term')\n",
    "doc_context_id = df_doc['doc_id'].to_list()    \n",
    "doc_context_encoded = mUSE_model(df_doc['doc'].to_list()).numpy()\n",
    "for lan in q_lan:\n",
    "    question_id = df_question[f'en-{lan}']['doc_id'].to_list()\n",
    "    questions = mUSE_model(df_question[f'en-{lan}']['question'].to_list()).numpy()\n",
    "    \n",
    "    top_1,top_5,top_10,mrr = set_fnc.evaluate(question_id,questions,doc_context_id,doc_context_encoded)\n",
    "\n",
    "    print(f'USE-{lan}')\n",
    "    precision = top_1 / len(questions)\n",
    "    print(f\"Traninng Score P@1: {precision:.3f}\")\n",
    "    precision = top_5 / len(questions)\n",
    "    print(f\"Traninng Score P@5: {precision:.3f}\")\n",
    "    precision = top_10 / len(questions)\n",
    "    print(f\"Traninng Score P@10: {precision:.3f}\")\n",
    "    print(f\"Mrr score:{mrr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence-Transformer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ST_model = SentenceTransformer('XXXXXXX')\n",
    "for lan in q_lan[:]:\n",
    "    set_fnc.sent_bert_encode(ST_model,'ST_model',lan,df_doc,df_question)\n",
    "    print('*'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
