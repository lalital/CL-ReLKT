{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training MRC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from simpletransformers.question_answering import QuestionAnsweringModel\n",
    "import json\n",
    "\n",
    "train_args = {\n",
    "    'learning_rate': 3e-5,\n",
    "    'num_train_epochs': 2,\n",
    "    'max_seq_length': 384,\n",
    "    'doc_stride': 128,\n",
    "    'overwrite_output_dir': True,\n",
    "    'reprocess_input_data': False,\n",
    "    'train_batch_size': 2,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "}\n",
    "\n",
    "model = QuestionAnsweringModel('xlmroberta', 'xlm-roberta-base',train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/XORQA/tydi_xor_gp/gp_squad_train_data.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_data = [item for topic in train_data['data'] for item in topic['paragraphs'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 14003/14003 [00:09<00:00, 1462.94it/s]\n",
      "add example index and unique id: 100%|██████████| 14003/14003 [00:00<00:00, 306678.08it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56a3fcfa6c04a358b5f5042b2e33da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5c082747c942749d9b3aaba7d83d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 0 of 2', max=7330.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/simpletransformers/question_answering/question_answering_model.py:752: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  model.parameters(), args.max_grad_norm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc3828354a243f19f8ce5ef606f8a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Epoch 1 of 2', max=7330.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1832, 2.089423501302842)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydict(dict):\n",
    "    def __str__(self):\n",
    "        return json.dumps(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../datasets/XORQA/tydi_xor_gp/gp_squad_dev_data.json', 'r') as f:\n",
    "    dev_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = [item for topic in dev_data['data'] for item in topic['paragraphs'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_edited = []\n",
    "for dev in dev_data:\n",
    "    for q in dev['qas']:\n",
    "        if q['lang'] != 'te' and q['lang'] != 'bn':\n",
    "            dev_data_edited.append(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_encode(encoder,context,bs = 10):\n",
    "    batch_encoded = []\n",
    "    for i in range(len(context)//bs+1):\n",
    "        batch_encoded.append(encoder(context[(i*bs):((i+1)*bs)]).numpy()) \n",
    " \n",
    "    batch_encoded = np.concatenate(batch_encoded,0)\n",
    "    return np.array(batch_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_search(question_encoded,doc_encoded):\n",
    "    query_map = np.full(doc_encoded.shape, question_encoded)\n",
    "    sim_score = np.array([*map(np.inner,query_map,doc_encoded)])\n",
    "    return np.argsort(sim_score)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'dev'\n",
    "# q_lan = ['ru_en','ru','ko','ko_en','bn','fi','te','ja']\n",
    "q_lan = ['ru','ko','fi','ja']\n",
    "# q_lan = ['ru_en']\n",
    "# q_lan = ['ru_en','ko_en','bn_en','fi_en','te_en','ja']\n",
    "corpus = 'XORQA'\n",
    "\n",
    "df_doc = pd.read_csv(f'../data_preprocess/{corpus}/{mode}/{corpus.lower()}_doc_en-en.csv') \n",
    "doc_raw = df_doc['doc'].to_list()\n",
    "\n",
    "# model = f'../models/{corpus}/best_model/finetuned_USE_XORQA_train_en-fi_top0-0_q-d-distillation_1000MSE_1e-4LR_TrueShuffle_teacher_best_teacher_batchsize_8_acc_metric'\n",
    "# module_load = hub.load(model)\n",
    "# model = f'../models/{corpus}/best_model/finetuned_USE_XORQA_train_en-ru_ko_ja_fi_top0-0_para_finetuned_USE_XORQA_train_en-ru_ko_ja_fi_top1-3_para_0.27margin_2WarmStep_cosLoss_RegFalse_FCFalse_small_0.27_1BatchUpdate_2hard_3shard_cos_HardUpdateFalse_SemiHardUpdateFalse_RegFalse'\n",
    "# teacher_model = hub.load(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = f'../models/{corpus}/finetuned_USE_XORQA_train_en-ru_ko_ja_fi_top0-0_q-d-distillation_1000MSE_0.1MSEq_1.0MSEd_0.01MSEqd_0.0005LR_teacher_best_teacher_batchsize_16_acc_metric_3term'\n",
    "module_load = hub.load(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encoded = batch_encode(module_load,df_doc['doc'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bbf6526f3e4230add8176e5ee8c4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2209.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "for dev_data in tqdm(dev_data_edited):\n",
    "    question = dev_data['qas'][0]['question']\n",
    "    question_encoded = module_load(question).numpy()\n",
    "    ranking = sim_search(question_encoded,context_encoded)\n",
    "    dev_data.update({\n",
    "        'context': doc_raw[ranking[0]]\n",
    "    })\n",
    "    final_data.append(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/final_data_doc_3term.json', 'w') as f:\n",
    "    json.dump(final_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passage retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'dev'\n",
    "# q_lan = ['ru_en','ru','ko','ko_en','bn','fi','te','ja']\n",
    "q_lan = ['ru','ko','fi','ja']\n",
    "# q_lan = ['ru_en']\n",
    "# q_lan = ['ru_en','ko_en','bn_en','fi_en','te_en','ja']\n",
    "corpus = 'XORQA'\n",
    "\n",
    "df_para = pd.read_csv(f'../data_preprocess/{corpus}/{mode}/{corpus.lower()}_para_en-en.csv') \n",
    "doc_raw = df_para['para'].to_list()\n",
    "\n",
    "# model = f'../models/{corpus}/best_model/finetuned_USE_XORQA_train_en-fi_top0-0_q-d-distillation_1000MSE_1e-4LR_TrueShuffle_teacher_best_teacher_batchsize_8_acc_metric'\n",
    "# module_load = hub.load(model)\n",
    "# model = f'../models/{corpus}/best_model/finetuned_USE_XORQA_train_en-ru_ko_ja_fi_top0-0_para_finetuned_USE_XORQA_train_en-ru_ko_ja_fi_top1-3_para_0.27margin_2WarmStep_cosLoss_RegFalse_FCFalse_small_0.27_1BatchUpdate_2hard_3shard_cos_HardUpdateFalse_SemiHardUpdateFalse_RegFalse'\n",
    "# teacher_model = hub.load(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encoded = batch_encode(module_load,df_para['para'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c09f5e020f4c78b70b78251e43b747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2209.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "for dev_data in tqdm(dev_data_edited):\n",
    "    question = dev_data['qas'][0]['question']\n",
    "    question_encoded = module_load(question).numpy()\n",
    "    ranking = sim_search(question_encoded,context_encoded)\n",
    "    dev_data.update({\n",
    "        'context': doc_raw[ranking[0]]\n",
    "    })\n",
    "    final_data.append(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/final_data_para_3term.json', 'w') as f:\n",
    "    json.dump(final_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dpr_df = pd.read_csv('results/final_context_dpr_doc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context_ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Где вручается Шно́белевская премия ?</td>\n",
       "      <td>The Nobel Prize in Chemistry () is awarded ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В каком театре работал Серге́й Ерва́ндович Кур...</td>\n",
       "      <td>Kurginyan was a member of the commission on ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Сколько длились Бои за город Дейр-эз-Зор?</td>\n",
       "      <td>The Battle of Ganja (Armenian:, '; ) or Elizab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Сколько статуй героев на площади Героев в Буда...</td>\n",
       "      <td>In Budapest, Hungary, the Heroes' Square, bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Когда была основана сборная Швейцарии по футболу?</td>\n",
       "      <td>The first football club in Switzerland is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>Mikä on Brasilian pinta-ala?</td>\n",
       "      <td>Brazil ( ), officially the Federative Republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>Missä Niue sijaitsee?</td>\n",
       "      <td>Mean sea level (MSL) (often shortened to sea l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>Kuinka kauan puberteetti keskimäärin kestää?</td>\n",
       "      <td>On average, girls begin puberty around ages 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>Kuka suomalainen pelasi Cercle Bruggessa 80-lu...</td>\n",
       "      <td>Lanier was drafted number one overall by the N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>Kuka loi Thor hahmon?</td>\n",
       "      <td>Thor is the son of Odin, king of Asgard. As Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0                  Где вручается Шно́белевская премия ?   \n",
       "1     В каком театре работал Серге́й Ерва́ндович Кур...   \n",
       "2             Сколько длились Бои за город Дейр-эз-Зор?   \n",
       "3     Сколько статуй героев на площади Героев в Буда...   \n",
       "4     Когда была основана сборная Швейцарии по футболу?   \n",
       "...                                                 ...   \n",
       "1719                       Mikä on Brasilian pinta-ala?   \n",
       "1720                              Missä Niue sijaitsee?   \n",
       "1721       Kuinka kauan puberteetti keskimäärin kestää?   \n",
       "1722  Kuka suomalainen pelasi Cercle Bruggessa 80-lu...   \n",
       "1723                              Kuka loi Thor hahmon?   \n",
       "\n",
       "                                            context_ans  \n",
       "0     The Nobel Prize in Chemistry () is awarded ann...  \n",
       "1     Kurginyan was a member of the commission on ne...  \n",
       "2     The Battle of Ganja (Armenian:, '; ) or Elizab...  \n",
       "3     In Budapest, Hungary, the Heroes' Square, bett...  \n",
       "4     The first football club in Switzerland is the ...  \n",
       "...                                                 ...  \n",
       "1719  Brazil ( ), officially the Federative Republic...  \n",
       "1720  Mean sea level (MSL) (often shortened to sea l...  \n",
       "1721  On average, girls begin puberty around ages 10...  \n",
       "1722  Lanier was drafted number one overall by the N...  \n",
       "1723  Thor is the son of Odin, king of Asgard. As Th...  \n",
       "\n",
       "[1724 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9297f39f634095821344fe5e515c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2209.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = []\n",
    "for dev_data in tqdm(dev_data_edited):\n",
    "    question = dev_data['qas'][0]['question']\n",
    "    try:\n",
    "        context = dpr_df[dpr_df['question']==question].context_ans.to_list()[0]\n",
    "    except:\n",
    "        context = 'XXXXXXXXXXXX'\n",
    "    dev_data.update({\n",
    "        'context': context\n",
    "    })\n",
    "    final_data.append(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/final_data_dpr_doc.json', 'w') as f:\n",
    "    json.dump(final_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,5\"\n",
    "from simpletransformers.question_answering import QuestionAnsweringModel\n",
    "import json\n",
    "model_qa = QuestionAnsweringModel('xlmroberta', 'outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydict(dict):\n",
    "    def __str__(self):\n",
    "        return json.dumps(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_data_doc_3term\n",
    "with open('results/final_data_para_3term.json', 'r') as f:\n",
    "    dev_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 2209/2209 [00:04<00:00, 481.09it/s]\n",
      "add example index and unique id: 100%|██████████| 2209/2209 [00:00<00:00, 526193.64it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e5749dc4db4056aea60eef22cadf1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Running Prediction', max=288.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = model_qa.predict(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission_list = []\n",
    "for pred in preds[0]:\n",
    "    submission_list.append([\n",
    "        pred['id'],pred['answer'][0]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission =  mydict(submission_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/submission_3term_para.json', 'w') as f:\n",
    "    json.dump(submission, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading examples from ../datasets/XORQA/xor_dev_retrieve_eng_span_v1_1.jsonl.txt\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "Evaluating the performance on te\n",
      "F1: 0.0, EM:0.0, BLEU:0.0\n",
      "Evaluating the performance on sw\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on th\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on fi\n",
      "F1: 20.77024118693934, EM:16.11111111111111, BLEU:18.39654272207708\n",
      "Evaluating the performance on id\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on ja\n",
      "F1: 26.177885343054186, EM:20.27027027027027, BLEU:18.568117888543963\n",
      "Evaluating the performance on ru\n",
      "F1: 26.39586790527993, EM:20.784313725490197, BLEU:21.83267580827505\n",
      "Evaluating the performance on ar\n",
      "F1: 28.107960500426582, EM:22.857142857142858, BLEU:23.22088481624749\n",
      "Evaluating the performance on en\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on bn\n",
      "F1: 0.0, EM:0.0, BLEU:0.0\n",
      "Evaluating the performance on ko\n",
      "F1: 27.845006985342778, EM:20.401337792642142, BLEU:24.51771999246487\n",
      "avg f1: 18.470994560148977\n",
      "avg em: 14.346310822379513\n",
      "avg bleu: 15.219420175372637\n"
     ]
    }
   ],
   "source": [
    "!python eval_xor_full.py \\\n",
    "--data_file ../datasets/XORQA/xor_dev_retrieve_eng_span_v1_1.jsonl.txt \\\n",
    "--pred_file results/submission_3term_para.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading examples from ../datasets/XORQA/xor_dev_retrieve_eng_span_v1_1.jsonl.txt\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "no answers\n",
      "Evaluating the performance on te\n",
      "F1: 0.0, EM:0.0, BLEU:0.0\n",
      "Evaluating the performance on sw\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on th\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on fi\n",
      "F1: 21.204852495155517, EM:16.666666666666664, BLEU:18.73531255333883\n",
      "Evaluating the performance on id\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on ja\n",
      "F1: 26.25071322838208, EM:20.60810810810811, BLEU:18.601477274816748\n",
      "Evaluating the performance on ru\n",
      "F1: 24.291907579665722, EM:18.823529411764707, BLEU:20.637614371394786\n",
      "Evaluating the performance on ar\n",
      "F1: 28.779998399610818, EM:23.142857142857142, BLEU:24.02042933650481\n",
      "Evaluating the performance on en\n",
      "F1: 0, EM:0, BLEU:0\n",
      "Evaluating the performance on bn\n",
      "F1: 0.0, EM:0.0, BLEU:0.0\n",
      "Evaluating the performance on ko\n",
      "F1: 28.48016751389703, EM:21.73913043478261, BLEU:25.23493018183097\n",
      "avg f1: 18.429662745244453\n",
      "avg em: 14.425755966311321\n",
      "avg bleu: 15.318537673983737\n"
     ]
    }
   ],
   "source": [
    "!python eval_xor_full.py \\\n",
    "--data_file ../datasets/XORQA/xor_dev_retrieve_eng_span_v1_1.jsonl.txt \\\n",
    "--pred_file results/submission_3term_doc.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | F1 | EM |\n",
    "| --- | --- | --- |\n",
    "| CL-ReLTK para|\n",
    "| RU | 21.1 |  16.8|\n",
    "| KO | 27.8 |  20.4|\n",
    "| JA | 26.1 |  20.2|\n",
    "| FI | 20.7 |  16.1|\n",
    "| AVG| 23.9 |  18.4|\n",
    "| CL-ReLTK doc|\n",
    "| RU | 24.3 |  18.8|\n",
    "| KO | 28.5 |  21.7|\n",
    "| JA | 26.3 |  20.6|\n",
    "| FI | 21.2 |  16.7|\n",
    "| AVG| 25.1 |  19.5|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
