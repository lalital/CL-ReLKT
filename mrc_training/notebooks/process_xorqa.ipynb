{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process XORQA dataset for Seq2Seq QA training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:24.770817Z",
     "iopub.status.busy": "2022-08-04T08:00:24.770377Z",
     "iopub.status.idle": "2022-08-04T08:00:26.932874Z",
     "shell.execute_reply": "2022-08-04T08:00:26.932219Z",
     "shell.execute_reply.started": "2022-08-04T08:00:24.770767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import json\n",
    "import glob\n",
    "import hashlib\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GroupShuffleSplit\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:26.934839Z",
     "iopub.status.busy": "2022-08-04T08:00:26.934482Z",
     "iopub.status.idle": "2022-08-04T08:00:26.950323Z",
     "shell.execute_reply": "2022-08-04T08:00:26.949476Z",
     "shell.execute_reply.started": "2022-08-04T08:00:26.934808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('5733be284776f41900661182')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:26.951880Z",
     "iopub.status.busy": "2022-08-04T08:00:26.951394Z",
     "iopub.status.idle": "2022-08-04T08:00:26.957983Z",
     "shell.execute_reply": "2022-08-04T08:00:26.957220Z",
     "shell.execute_reply.started": "2022-08-04T08:00:26.951842Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hash(text):\n",
    "    import hashlib\n",
    "    return hashlib.sha256(text.encode()).hexdigest()[:24]\n",
    "get_hash('a')\n",
    "\n",
    "def get_qa_hash(question, context):\n",
    "    return get_hash('question:' + question + ' ' + 'context:' + context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:26.961581Z",
     "iopub.status.busy": "2022-08-04T08:00:26.961094Z",
     "iopub.status.idle": "2022-08-04T08:00:36.411141Z",
     "shell.execute_reply": "2022-08-04T08:00:36.410034Z",
     "shell.execute_reply.started": "2022-08-04T08:00:26.961532Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../exploratory/online_prompt/notebooks/')\n",
    "from exploring_sentence_level import (\n",
    "    load_model,\n",
    "    mine_prompt_gt,  \n",
    "    segment_sentence,\n",
    "    run_online_prompt_mining\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:36.412996Z",
     "iopub.status.busy": "2022-08-04T08:00:36.412652Z",
     "iopub.status.idle": "2022-08-04T08:00:36.666705Z",
     "shell.execute_reply": "2022-08-04T08:00:36.665757Z",
     "shell.execute_reply.started": "2022-08-04T08:00:36.412964Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "XORQA_BASE_DIR = '../data/xorqa/en/tydi_xor_gp/'\n",
    "xorqa_xx = {\n",
    "    'train': json.load(open(os.path.join(XORQA_BASE_DIR, 'gp_squad_train_data.json'), 'r'))['data'],\n",
    "      'val': json.load(open(os.path.join(XORQA_BASE_DIR, 'gp_squad_dev_data.json'), 'r'))['data'],   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:36.668897Z",
     "iopub.status.busy": "2022-08-04T08:00:36.668438Z",
     "iopub.status.idle": "2022-08-04T08:00:36.677322Z",
     "shell.execute_reply": "2022-08-04T08:00:36.676463Z",
     "shell.execute_reply.started": "2022-08-04T08:00:36.668852Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'title:Vamsy_parentSection:Introduction_sectionName:Career._sectionIndex:2',\n",
       " 'paragraphs': [{'context': 'He has published a short stories compilation called \"Maa Pasalapudi Kathalu\". Besides that compilation, Vamsy has written a wide variety of short stories since 1974 when he was 18 years old. His major works include \"Mahallo kokila\", \"Manchupallaki\", \"Aa Naati Vaana Chinukulu\", \"Venditera Kathalu\" (original scripts of \"Sankarabharanam\" and \"Anveshana\"), \"Vennela Bomma\", \"Gokulam lo Radha\", \"Ravvala konda\", \"Sree seetarama lanchi service Rajahmundry\", \"Manyam rani\", \"Rangularatnam\". He has penned around 150 short stories published in swathi weekly under title \"Maa Diguwa Godavari Kathalu\" For his contributions to the art of story telling with a native approach through his books he was bestowed with \"Sripada Puraskhaaram\" at Rajamundry on 17 April 2011.',\n",
       "   'qas': [{'question': 'మా పసలపూడి కథలు పుస్తకమును ఎవరు రచించారు?',\n",
       "     'answers': [{'text': 'Vamsy', 'answer_start': 104}],\n",
       "     'id': '-107019484199702154',\n",
       "     'lang': 'te',\n",
       "     'split': 'train'}]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_xx['train'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:36.679016Z",
     "iopub.status.busy": "2022-08-04T08:00:36.678559Z",
     "iopub.status.idle": "2022-08-04T08:00:36.684649Z",
     "shell.execute_reply": "2022-08-04T08:00:36.683700Z",
     "shell.execute_reply.started": "2022-08-04T08:00:36.678982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "title = 'title:Vamsy_parentSection:Introduction_sectionName:Career._sectionIndex:2'\n",
    "document_title = re.search(r'(title:)(.+)(Section:)', title).group(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:36.686263Z",
     "iopub.status.busy": "2022-08-04T08:00:36.685712Z",
     "iopub.status.idle": "2022-08-04T08:00:36.691549Z",
     "shell.execute_reply": "2022-08-04T08:00:36.690834Z",
     "shell.execute_reply.started": "2022-08-04T08:00:36.686230Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_xorqa_answer_str(context, qas):\n",
    "    context_qa_pairs = []\n",
    "    for qa in qas:\n",
    "        question = qa['question']\n",
    "        lang = qa['lang'].strip()\n",
    "        answer = qa['answers'][0]['text']\n",
    "        answer_start = qa['answers'][0]['answer_start']\n",
    "        answers = qa['answers']\n",
    "        context_qa_pairs.append((context, question, answer, answer_start, lang, answers))\n",
    "    return context_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:36.693396Z",
     "iopub.status.busy": "2022-08-04T08:00:36.692838Z",
     "iopub.status.idle": "2022-08-04T08:00:46.209232Z",
     "shell.execute_reply": "2022-08-04T08:00:46.208547Z",
     "shell.execute_reply.started": "2022-08-04T08:00:36.693362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xorqa_xx_dataset = defaultdict(lambda: { 'train': [], 'val': [] })\n",
    "\n",
    "for split_name in ['train', 'val']:\n",
    "    for i, item in enumerate(xorqa_xx[split_name]):\n",
    "        paragraphs = item['paragraphs']\n",
    "#         print('.' ,end='')\n",
    "        full_title = item['title']\n",
    "        document_title = re.search(r'(title:)(.+)(Section:)', full_title).group(2)\n",
    "        for j, paragraph in enumerate(paragraphs):\n",
    "\n",
    "            context = paragraph['context']\n",
    "            context_qa_pairs = get_xorqa_answer_str(context=context, qas=paragraph['qas'])\n",
    "\n",
    "            for context_qa_pair in context_qa_pairs:\n",
    "                context, question, answer, answer_start, lang, answers = context_qa_pair\n",
    "                lang = lang\n",
    "                gt_sentence = mine_prompt_gt((context, question, answer, answer_start))\n",
    "                qa_item = {\n",
    "                     'question': question,\n",
    "                     'lang': lang,\n",
    "                     'context': context,\n",
    "                     'segmented_context': segment_sentence(context),\n",
    "                     'answer': answer,\n",
    "                     'answer_start': answer_start,\n",
    "                     'gt_sentence': gt_sentence,\n",
    "                     'document_title': document_title,\n",
    "                     'full_title': full_title,\n",
    "                     'answers': answers\n",
    "                }\n",
    "                xorqa_xx_dataset[lang][split_name].append(qa_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:46.217422Z",
     "iopub.status.busy": "2022-08-04T08:00:46.216690Z",
     "iopub.status.idle": "2022-08-04T08:00:46.225676Z",
     "shell.execute_reply": "2022-08-04T08:00:46.224807Z",
     "shell.execute_reply.started": "2022-08-04T08:00:46.217314Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bn', 'ja', 'ko', 'ru', 'fi', 'ar', 'te']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XORQA_LANGS = list(xorqa_xx_dataset.keys())\n",
    "XORQA_LANGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:46.227118Z",
     "iopub.status.busy": "2022-08-04T08:00:46.226670Z",
     "iopub.status.idle": "2022-08-04T08:00:46.235442Z",
     "shell.execute_reply": "2022-08-04T08:00:46.234613Z",
     "shell.execute_reply.started": "2022-08-04T08:00:46.227075Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang= bn\n",
      "split_name=train , n_questions: 2474\n",
      "split_name=val   , n_questions: 523\n",
      "\n",
      "\n",
      "lang= ja\n",
      "split_name=train , n_questions: 1927\n",
      "split_name=val   , n_questions: 371\n",
      "\n",
      "\n",
      "lang= ko\n",
      "split_name=train , n_questions: 2395\n",
      "split_name=val   , n_questions: 460\n",
      "\n",
      "\n",
      "lang= ru\n",
      "split_name=train , n_questions: 1744\n",
      "split_name=val   , n_questions: 384\n",
      "\n",
      "\n",
      "lang= fi\n",
      "split_name=train , n_questions: 1855\n",
      "split_name=val   , n_questions: 509\n",
      "\n",
      "\n",
      "lang= ar\n",
      "split_name=train , n_questions: 2303\n",
      "split_name=val   , n_questions: 485\n",
      "\n",
      "\n",
      "lang= te\n",
      "split_name=train , n_questions: 1305\n",
      "split_name=val   , n_questions: 376\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang in XORQA_LANGS:\n",
    "    print(f'lang= {lang}')\n",
    "    for split_name in ['train', 'val']:\n",
    "\n",
    "        n_questions = len(xorqa_xx_dataset[lang][split_name])\n",
    "        print(f'split_name={split_name:6}, n_questions: {n_questions}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting strategy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set => training set and validation set\n",
    "\n",
    "Val set = test set\n",
    "\n",
    "------\n",
    "\n",
    "A Disjoint set of documents for training, validation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:46.236734Z",
     "iopub.status.busy": "2022-08-04T08:00:46.236372Z",
     "iopub.status.idle": "2022-08-04T08:00:46.253287Z",
     "shell.execute_reply": "2022-08-04T08:00:46.252398Z",
     "shell.execute_reply.started": "2022-08-04T08:00:46.236703Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: bn, 2,474\n",
      "lang: ja, 1,927\n",
      "lang: ko, 2,395\n",
      "lang: ru, 1,744\n",
      "lang: fi, 1,855\n",
      "lang: ar, 2,303\n",
      "lang: te, 1,305\n",
      "\n",
      "Total number of QA example in train/val set: 14,003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14003"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_train_val_set = []\n",
    "xorqa_train_val_groups = []\n",
    "per_lang_q_counter = {}\n",
    "for lang in XORQA_LANGS:\n",
    "\n",
    "    for split_name in ['train']:\n",
    "        qas = xorqa_xx_dataset[lang][split_name]\n",
    "        xorqa_train_val_set.extend(qas)\n",
    "        xorqa_train_val_groups.extend(list(map(lambda x: x['document_title'], qas)))\n",
    "        print(f'lang: {lang}, {len(qas):,}')\n",
    "        per_lang_q_counter[lang] = len(qas)\n",
    "print(f'\\nTotal number of QA example in train/val set: {len(xorqa_train_val_set):,}')\n",
    "len(xorqa_train_val_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:46.254833Z",
     "iopub.status.busy": "2022-08-04T08:00:46.254383Z",
     "iopub.status.idle": "2022-08-04T08:00:46.267306Z",
     "shell.execute_reply": "2022-08-04T08:00:46.265608Z",
     "shell.execute_reply.started": "2022-08-04T08:00:46.254804Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: bn, 523\n",
      "lang: ja, 371\n",
      "lang: ko, 460\n",
      "lang: ru, 384\n",
      "lang: fi, 509\n",
      "lang: ar, 485\n",
      "lang: te, 376\n",
      "\n",
      "Total number of QA example in test set: 3,108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3108"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_test_set = []\n",
    "xorqa_test_groups = []\n",
    "for lang in XORQA_LANGS:\n",
    "\n",
    "    for split_name in ['val']:\n",
    "        qas = xorqa_xx_dataset[lang][split_name]\n",
    "        xorqa_test_set.extend(qas)\n",
    "        xorqa_test_groups.extend(list(map(lambda x: x['document_title'], qas)))\n",
    "        \n",
    "        print(f'lang: {lang}, {len(qas):,}')\n",
    "print(f'\\nTotal number of QA example in test set: {len(xorqa_test_set):,}')\n",
    "len(xorqa_test_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:46.270307Z",
     "iopub.status.busy": "2022-08-04T08:00:46.269703Z",
     "iopub.status.idle": "2022-08-04T08:00:46.285740Z",
     "shell.execute_reply": "2022-08-04T08:00:46.284923Z",
     "shell.execute_reply.started": "2022-08-04T08:00:46.270258Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(663, 12232)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(xorqa_train_val_groups).intersection(set(xorqa_test_groups))), \\\n",
    "len(list((set(xorqa_train_val_groups).union(set(xorqa_test_groups)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:46.287412Z",
     "iopub.status.busy": "2022-08-04T08:00:46.287084Z",
     "iopub.status.idle": "2022-08-04T08:00:46.293823Z",
     "shell.execute_reply": "2022-08-04T08:00:46.293172Z",
     "shell.execute_reply.started": "2022-08-04T08:00:46.287378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'మా పసలపూడి కథలు పుస్తకమును ఎవరు రచించారు?',\n",
       " 'lang': 'te',\n",
       " 'context': 'He has published a short stories compilation called \"Maa Pasalapudi Kathalu\". Besides that compilation, Vamsy has written a wide variety of short stories since 1974 when he was 18 years old. His major works include \"Mahallo kokila\", \"Manchupallaki\", \"Aa Naati Vaana Chinukulu\", \"Venditera Kathalu\" (original scripts of \"Sankarabharanam\" and \"Anveshana\"), \"Vennela Bomma\", \"Gokulam lo Radha\", \"Ravvala konda\", \"Sree seetarama lanchi service Rajahmundry\", \"Manyam rani\", \"Rangularatnam\". He has penned around 150 short stories published in swathi weekly under title \"Maa Diguwa Godavari Kathalu\" For his contributions to the art of story telling with a native approach through his books he was bestowed with \"Sripada Puraskhaaram\" at Rajamundry on 17 April 2011.',\n",
       " 'segmented_context': ['He has published a short stories compilation called \"Maa Pasalapudi Kathalu\".',\n",
       "  'Besides that compilation, Vamsy has written a wide variety of short stories since 1974 when he was 18 years old.',\n",
       "  'His major works include \"Mahallo kokila\", \"Manchupallaki\", \"Aa Naati Vaana Chinukulu\", \"Venditera Kathalu\" (original scripts of \"Sankarabharanam\" and \"Anveshana\"), \"Vennela Bomma\", \"Gokulam lo Radha\", \"Ravvala konda\", \"Sree seetarama lanchi service Rajahmundry\", \"Manyam rani\", \"Rangularatnam\".',\n",
       "  'He has penned around 150 short stories published in swathi weekly under title \"Maa Diguwa Godavari Kathalu\" For his contributions to the art of story telling with a native approach through his books he was bestowed with \"Sripada Puraskhaaram\" at Rajamundry on 17 April 2011.'],\n",
       " 'answer': 'Vamsy',\n",
       " 'answer_start': 104,\n",
       " 'gt_sentence': 'Besides that compilation, Vamsy has written a wide variety of short stories since 1974 when he was 18 years old.',\n",
       " 'document_title': 'Vamsy_parent',\n",
       " 'full_title': 'title:Vamsy_parentSection:Introduction_sectionName:Career._sectionIndex:2',\n",
       " 'answers': [{'text': 'Vamsy', 'answer_start': 104}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xorqa_train_val_set[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:00:46.295267Z",
     "iopub.status.busy": "2022-08-04T08:00:46.294853Z",
     "iopub.status.idle": "2022-08-04T08:00:46.302871Z",
     "shell.execute_reply": "2022-08-04T08:00:46.302087Z",
     "shell.execute_reply.started": "2022-08-04T08:00:46.295233Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14003,\n",
       " ['WikiLeaks_parent',\n",
       "  'World War II_parent',\n",
       "  '1948 Arab–Israeli War_parent',\n",
       "  'History of capitalism_parent',\n",
       "  'World War I_parent',\n",
       "  'Objections to evolution_parent',\n",
       "  'Evolution_parent',\n",
       "  'Republican Party (United States)_parent',\n",
       "  '1948 Arab–Israeli War_parent',\n",
       "  'Jimmy Wales_parent',\n",
       "  'History of Islam_parent',\n",
       "  'Great Salt Lake_parent',\n",
       "  'Wikipedia_parent',\n",
       "  'Political career of Arnold Schwarzenegger_parent',\n",
       "  'On the Origin of Species_parent',\n",
       "  'Athens_parent',\n",
       "  'Motivation_parent',\n",
       "  'Feminist sex wars_parent',\n",
       "  'Raja Harishchandra_parent',\n",
       "  'History of evolutionary thought_parent',\n",
       "  'Ted Hughes_parent',\n",
       "  'History of Apple Inc._parent',\n",
       "  'Television network_parent',\n",
       "  'John Maynard Keynes_parent',\n",
       "  'History of the United States Republican Party_parent',\n",
       "  'Al-Qaeda_parent',\n",
       "  'Indo-Pakistani Naval War of 1971_parent',\n",
       "  'Moscow_parent',\n",
       "  'Byzantine Empire_parent',\n",
       "  'History of India_parent',\n",
       "  'Origen_parent',\n",
       "  'Linux_parent',\n",
       "  '1st Dalai Lama_parent',\n",
       "  'Damascus_parent',\n",
       "  'Pornography in Bangladesh_parent',\n",
       "  'Detroit_parent',\n",
       "  'Television_parent',\n",
       "  'Burmese language_parent',\n",
       "  'Zero-point energy_parent',\n",
       "  'East Pakistan_parent'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xorqa_train_val_groups), xorqa_train_val_groups[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:54.715350Z",
     "iopub.status.busy": "2022-08-04T08:08:54.715033Z",
     "iopub.status.idle": "2022-08-04T08:08:54.719013Z",
     "shell.execute_reply": "2022-08-04T08:08:54.718123Z",
     "shell.execute_reply.started": "2022-08-04T08:08:54.715317Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:08:55.309318Z",
     "iopub.status.busy": "2022-08-04T08:08:55.308859Z",
     "iopub.status.idle": "2022-08-04T08:08:55.368838Z",
     "shell.execute_reply": "2022-08-04T08:08:55.368132Z",
     "shell.execute_reply.started": "2022-08-04T08:08:55.309283Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "random_seed: 68\n",
      "N_doc_train : 9,811 (89.9927)\n",
      "N_doc_validation : 1,091 (10.0073)\n",
      "\n",
      "N_paragraphs_train : 12,603 (90.0021)\n",
      "N_paragraphs_validation : 1,400 (9.9979)\n",
      "\n",
      "total_paragraphs: 14,003\n",
      "total_docs: 10,902\n",
      "\n",
      "\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from math import isclose\n",
    "from tqdm import tqdm\n",
    "c =0\n",
    "for random_seed in tqdm([SEED]):\n",
    "    X = xorqa_train_val_set\n",
    "    groups = xorqa_train_val_groups\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.90, random_state=random_seed)\n",
    "    gss.get_n_splits(X)\n",
    "\n",
    "    xorqa_group_split = {}\n",
    "    for train_index, test_index in gss.split(X, groups=groups):\n",
    "#         print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "\n",
    "#         print(train_index[0:20], train_index[-20:], )\n",
    "\n",
    "        xorqa_group_split['train'], xorqa_group_split['validation'] = [ X[idx] for idx in train_index ], [ X[idx] for idx in test_index ]\n",
    "\n",
    "\n",
    "    per_split_doc_title_counter = defaultdict(lambda: set())\n",
    "    per_split_paragraph_in_doc_counter = defaultdict(lambda: Counter())\n",
    "\n",
    "\n",
    "    for split_name in ['train', 'validation']:\n",
    "\n",
    "        for qa in xorqa_group_split[split_name]:\n",
    "            document_title = qa['document_title']\n",
    "            per_split_doc_title_counter[split_name].add(document_title)\n",
    "            per_split_paragraph_in_doc_counter[split_name][document_title] += 1\n",
    "\n",
    "    N_doc_train = len(per_split_doc_title_counter['train'])\n",
    "    N_doc_validation = len(per_split_doc_title_counter['validation'])\n",
    "\n",
    "    N_paragraphs_train = sum(per_split_paragraph_in_doc_counter['train'].values())\n",
    "    N_paragraphs_validation = sum(per_split_paragraph_in_doc_counter['validation'].values())\n",
    "\n",
    "    total_docs, total_paragraphs = N_doc_train + N_doc_validation, N_paragraphs_train + N_paragraphs_validation\n",
    "\n",
    "\n",
    "    \n",
    "    n_paragraph_train_ratio = (N_paragraphs_train/total_paragraphs)*100\n",
    "    n_paragraph_train_validation = (N_paragraphs_validation/total_paragraphs)*100\n",
    "       \n",
    "\n",
    "    if isclose(n_paragraph_train_ratio, 90.0 , abs_tol=0.0024) and n_paragraph_train_ratio >=90.0 and c <=5:\n",
    "\n",
    "        print(f'\\nrandom_seed: {random_seed}')\n",
    "\n",
    "        print(f'N_doc_train : {N_doc_train:,} ({(N_doc_train/total_docs)*100:.4f})')\n",
    "        print(f'N_doc_validation : {N_doc_validation:,} ({(N_doc_validation/total_docs)*100:.4f})')\n",
    "        print(f'\\nN_paragraphs_train : {N_paragraphs_train:,} ({n_paragraph_train_ratio:.4f})')\n",
    "        print(f'N_paragraphs_validation : {N_paragraphs_validation:,} ({n_paragraph_train_validation:.4f})')\n",
    "\n",
    "        print(f'\\ntotal_paragraphs: {total_paragraphs:,}')\n",
    "        print(f'total_docs: {total_docs:,}')\n",
    "        print('\\n')\n",
    "        print('-'*40)\n",
    "#         break\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert into Json format (for Dataset.loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "```\n",
    "5733be284776f41900661182\n",
    "\n",
    "University_of_Notre_Dame\n",
    "\n",
    "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
    "\n",
    "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
    "\n",
    "{ \"text\": [ \"Saint Bernadette Soubirous\" ], \"answer_start\": [ 515 ] }\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:09:03.266264Z",
     "iopub.status.busy": "2022-08-04T08:09:03.265896Z",
     "iopub.status.idle": "2022-08-04T08:09:03.272353Z",
     "shell.execute_reply": "2022-08-04T08:09:03.271559Z",
     "shell.execute_reply.started": "2022-08-04T08:09:03.266232Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_qa_item_to_datasets_format(qa_item):\n",
    "    title = qa_item['document_title']\n",
    "    question, context, answers = qa_item['question'], qa_item['context'], qa_item['answers']\n",
    "    lang =  qa_item['lang']\n",
    "    return {\n",
    "        'id': get_qa_hash(question, context),\n",
    "        'lang': lang,\n",
    "        'title': title,\n",
    "        'context': context,\n",
    "        'question': question,\n",
    "        'answers': { 'text': [_answer['text'] for _answer in answers],\n",
    "                     'answer_start': [_answer['answer_start'] for _answer in answers]\n",
    "                   }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:09:03.410549Z",
     "iopub.status.busy": "2022-08-04T08:09:03.410099Z",
     "iopub.status.idle": "2022-08-04T08:09:03.601306Z",
     "shell.execute_reply": "2022-08-04T08:09:03.600591Z",
     "shell.execute_reply.started": "2022-08-04T08:09:03.410513Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xorqa_group_split['test'] = xorqa_test_set\n",
    "\n",
    "xorqa_processed_dataset = {\n",
    "   split_name: list(map(convert_qa_item_to_datasets_format, xorqa_group_split[split_name])) \\\n",
    "    for split_name in ['train','validation', 'test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:09:18.066627Z",
     "iopub.status.busy": "2022-08-04T08:09:18.066299Z",
     "iopub.status.idle": "2022-08-04T08:09:18.746832Z",
     "shell.execute_reply": "2022-08-04T08:09:18.746183Z",
     "shell.execute_reply.started": "2022-08-04T08:09:18.066590Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split_name in ['train','validation', 'test']:\n",
    "    os.makedirs('../data/xorqa/datasets_format/', exist_ok=True)\n",
    "    with open(f'../data/xorqa/datasets_format/{split_name}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump({ 'meta': {\n",
    "            'train_split_ratio': 0.9,\n",
    "            'val_split_ratio': 0.1,\n",
    "            'split_type': 'GroupShuffleSplit',\n",
    "            'split_seed': 68,\n",
    "            'date': '04/08/2022',\n",
    "        },\n",
    "            'data': xorqa_processed_dataset[split_name] }, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distribution of questions for all langs for train, validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:09:20.207282Z",
     "iopub.status.busy": "2022-08-04T08:09:20.206970Z",
     "iopub.status.idle": "2022-08-04T08:09:20.218833Z",
     "shell.execute_reply": "2022-08-04T08:09:20.218079Z",
     "shell.execute_reply.started": "2022-08-04T08:09:20.207246Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lang_counter = defaultdict()\n",
    "lang_counter_percentage = defaultdict(lambda: defaultdict())                    \n",
    "\n",
    "for split_name in ['train','validation', 'test']:\n",
    "    \n",
    "    lang_counter[split_name] = Counter(list(map(lambda x: x['lang'], xorqa_processed_dataset[split_name])))\n",
    "    \n",
    "    for lang in XORQA_LANGS:\n",
    "        if split_name in ['train','validation']:\n",
    "            lang_counter_percentage[split_name][lang] = {\n",
    "                'lang': lang,\n",
    "                'lang_counter': lang_counter[split_name][lang],\n",
    "                'per_lang_q_counter': per_lang_q_counter[lang],\n",
    "                'percentage': lang_counter[split_name][lang] / per_lang_q_counter[lang]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T08:09:21.410755Z",
     "iopub.status.busy": "2022-08-04T08:09:21.410407Z",
     "iopub.status.idle": "2022-08-04T08:09:21.419570Z",
     "shell.execute_reply": "2022-08-04T08:09:21.418930Z",
     "shell.execute_reply.started": "2022-08-04T08:09:21.410723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7fbcc9b739e0>,\n",
      "            { 'train': defaultdict(None,\n",
      "                                   { 'ar': { 'lang': 'ar',\n",
      "                                             'lang_counter': 2077,\n",
      "                                             'per_lang_q_counter': 2303,\n",
      "                                             'percentage': 0.9018671298306556},\n",
      "                                     'bn': { 'lang': 'bn',\n",
      "                                             'lang_counter': 2203,\n",
      "                                             'per_lang_q_counter': 2474,\n",
      "                                             'percentage': 0.8904607922392886},\n",
      "                                     'fi': { 'lang': 'fi',\n",
      "                                             'lang_counter': 1676,\n",
      "                                             'per_lang_q_counter': 1855,\n",
      "                                             'percentage': 0.9035040431266846},\n",
      "                                     'ja': { 'lang': 'ja',\n",
      "                                             'lang_counter': 1727,\n",
      "                                             'per_lang_q_counter': 1927,\n",
      "                                             'percentage': 0.8962117280747276},\n",
      "                                     'ko': { 'lang': 'ko',\n",
      "                                             'lang_counter': 2163,\n",
      "                                             'per_lang_q_counter': 2395,\n",
      "                                             'percentage': 0.9031315240083507},\n",
      "                                     'ru': { 'lang': 'ru',\n",
      "                                             'lang_counter': 1574,\n",
      "                                             'per_lang_q_counter': 1744,\n",
      "                                             'percentage': 0.9025229357798165},\n",
      "                                     'te': { 'lang': 'te',\n",
      "                                             'lang_counter': 1183,\n",
      "                                             'per_lang_q_counter': 1305,\n",
      "                                             'percentage': 0.9065134099616858}}),\n",
      "              'validation': defaultdict(None,\n",
      "                                        { 'ar': { 'lang': 'ar',\n",
      "                                                  'lang_counter': 226,\n",
      "                                                  'per_lang_q_counter': 2303,\n",
      "                                                  'percentage': 0.09813287016934433},\n",
      "                                          'bn': { 'lang': 'bn',\n",
      "                                                  'lang_counter': 271,\n",
      "                                                  'per_lang_q_counter': 2474,\n",
      "                                                  'percentage': 0.1095392077607114},\n",
      "                                          'fi': { 'lang': 'fi',\n",
      "                                                  'lang_counter': 179,\n",
      "                                                  'per_lang_q_counter': 1855,\n",
      "                                                  'percentage': 0.09649595687331536},\n",
      "                                          'ja': { 'lang': 'ja',\n",
      "                                                  'lang_counter': 200,\n",
      "                                                  'per_lang_q_counter': 1927,\n",
      "                                                  'percentage': 0.10378827192527244},\n",
      "                                          'ko': { 'lang': 'ko',\n",
      "                                                  'lang_counter': 232,\n",
      "                                                  'per_lang_q_counter': 2395,\n",
      "                                                  'percentage': 0.09686847599164927},\n",
      "                                          'ru': { 'lang': 'ru',\n",
      "                                                  'lang_counter': 170,\n",
      "                                                  'per_lang_q_counter': 1744,\n",
      "                                                  'percentage': 0.09747706422018348},\n",
      "                                          'te': { 'lang': 'te',\n",
      "                                                  'lang_counter': 122,\n",
      "                                                  'per_lang_q_counter': 1305,\n",
      "                                                  'percentage': 0.09348659003831418}})})\n"
     ]
    }
   ],
   "source": [
    "pprint(lang_counter_percentage, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
