{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f68370e0-6030-4331-91c5-1ebb0ef13a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import datasets\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers.trainer_utils import EvalLoopOutput, EvalPrediction, get_last_checkpoint\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4040c-d82f-408c-a8f0-7abc7ccbbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"squad\")\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd5c7e3-20c8-4a1f-87d0-1361d49efe70",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1732608-901f-4b48-b49c-f86305976cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_answer_str(context, qas):\n",
    "    context_qa_pairs = []\n",
    "    for qa in qas:\n",
    "        question = qa['question']\n",
    "        answer = qa['answers'][0]['text']\n",
    "        answer_start = qa['answers'][0]['answer_start']\n",
    "        context_qa_pairs.append((context, question, answer, answer_start))\n",
    "    return context_qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e57a76-13b2-467b-b112-fe8c7fe7e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ab504a7-89bc-4361-807a-4b4a1e253ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "XQUAD_BASE_DIR = '/ist/ist-share/scads/aires/CL-ReLKT/mrc_training/data/xquad/xx/'\n",
    "XQUAD_CACHE_DIR = '/ist/ist-share/scads/aires/CL-ReLKT/mrc_training/data/xquad/_cache/'\n",
    "xquad_en = json.load(open(os.path.join(XQUAD_BASE_DIR, 'xquad.en.json'), 'r'))\n",
    "xquad_en.keys(), \\\n",
    "xquad_en['version']\n",
    "\n",
    "\n",
    "xquad_xx = {}\n",
    "XQUAD_LANGS = ['ar', 'de', 'el', 'en', 'es', 'hi', 'ro', 'ru', 'th', 'tr', 'vi', 'zh']\n",
    "for lang in XQUAD_LANGS:\n",
    "    xquad_xx[f'{lang}'] = json.load(open(os.path.join(XQUAD_BASE_DIR, f'xquad.{lang}.json'), 'r'))['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "437eb66f-c0db-4faa-9179-d7caae8c98ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': str, 'context': str, 'answer': str}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = datasets.Features({'question': str, 'context': str, 'answer': str})\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b3f4348-244e-4149-bb56-300d1790508d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24b04c42-08f8-433f-b45b-bfd13839bef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_datasets \u001b[38;5;241m=\u001b[39m { lang: datasets\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_dict(mapping\u001b[38;5;241m=\u001b[39mdata) \u001b[38;5;28;01mfor\u001b[39;00m lang, data \u001b[38;5;129;01min\u001b[39;00m xquad_xx\u001b[38;5;241m.\u001b[39mitems() }\n\u001b[1;32m      2\u001b[0m raw_datasets\u001b[38;5;241m.\u001b[39mkeys()\n",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_datasets \u001b[38;5;241m=\u001b[39m { lang: \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m lang, data \u001b[38;5;129;01min\u001b[39;00m xquad_xx\u001b[38;5;241m.\u001b[39mitems() }\n\u001b[1;32m      2\u001b[0m raw_datasets\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/.conda/envs/t5.mrc/lib/python3.9/site-packages/datasets/arrow_dataset.py:857\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     mapping \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mencode_batch(mapping)\n\u001b[1;32m    855\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    856\u001b[0m     col: OptimizedTypedSequence(data, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mfeatures[col] \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, col\u001b[38;5;241m=\u001b[39mcol)\n\u001b[0;32m--> 857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col, data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()\n\u001b[1;32m    858\u001b[0m }\n\u001b[1;32m    859\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m InMemoryTable\u001b[38;5;241m.\u001b[39mfrom_pydict(mapping\u001b[38;5;241m=\u001b[39mmapping)\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "raw_datasets = { lang: datasets.Dataset.from_dict(mapping=data) for lang, data in xquad_xx.items() }\n",
    "raw_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6756c4dd-3ad7-4670-9e28-e53479921aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60096e80-cb85-461d-be6a-af698a69408b",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce89fe85-b679-46e7-8506-3c724339529d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: What is the capital city of Thailand? context: เมืองหลวงของราชอาณาจักรไทย คือกรุงเทพมหานคร (Bangkok; BKK)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_input(_question:str, _context:str):\n",
    "    return \" \".join([\"question:\", _question.lstrip(), \"context:\", _context.lstrip()])\n",
    "\n",
    "generate_input('What is the capital city of Thailand?','เมืองหลวงของราชอาณาจักรไทย คือกรุงเทพมหานคร (Bangkok; BKK)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da5e2ff-df66-4a22-8984-f4cc99bf44cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='/ist/ist-share/scads/aires/CL-ReLKT/mrc_training/models/mt5-large/', vocab_size=250100, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRETRAINED_TOKENIZER_DIR = '/ist/ist-share/scads/aires/CL-ReLKT/mrc_training/models/mt5-large/'\n",
    "tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_TOKENIZER_DIR)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b3eeec-edc3-4e71-b811-62e68b7f86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_squad_batch(\n",
    "    examples,\n",
    "    question_column: str,\n",
    "    context_column: str,\n",
    "    answer_column: str,\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    questions = examples[question_column]\n",
    "    contexts = examples[context_column]\n",
    "    answers = examples[answer_column]\n",
    "\n",
    "    def generate_input(_question, _context):\n",
    "        return \" \".join([\"question:\", _question.lstrip(), \"context:\", _context.lstrip()])\n",
    "\n",
    "    inputs = [generate_input(question, context) for question, context in zip(questions, contexts)]\n",
    "    targets = [answer[\"text\"][0] if len(answer[\"text\"]) > 0 else \"\" for answer in answers]\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c8f7710-a12e-4f9e-8fd5-1ae6ddb1abb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['question: What is the capital city of Thailand? context: เมืองหลวงของราชอาณาจักรไทย คือกรุงเทพมหานคร (Bangkok; BKK)',\n",
       "  'question: Who is the governor of Bangkok? context: เมืองหลวงของราชอาณาจักรไทย คือกรุงเทพมหานคร (Bangkok; BKK)'],\n",
       " ['กรุงเทพมหานคร', 'ชัชชาติ สิทธิพันธุ์'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples ={\n",
    "    'question': ['What is the capital city of Thailand?', 'Who is the governor of Bangkok?'],\n",
    "    'context': ['เมืองหลวงของราชอาณาจักรไทย คือกรุงเทพมหานคร (Bangkok; BKK)', 'เมืองหลวงของราชอาณาจักรไทย คือกรุงเทพมหานคร (Bangkok; BKK)'],\n",
    "    'answers': [{'text': ['กรุงเทพมหานคร'] }, {'text': ['ชัชชาติ สิทธิพันธุ์'] }],\n",
    "}\n",
    "preprocess_squad_batch(examples=examples,  question_column='question',\n",
    "    context_column='context',\n",
    "    answer_column='answers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2419289-655d-45cb-98e2-88c0adc35bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512\n",
    "max_answer_length = 30\n",
    "padding=True\n",
    "\n",
    "def preprocess_function(examples, question_column, context_column, answer_column):\n",
    "    inputs, targets = preprocess_squad_batch(examples, question_column, context_column, answer_column)\n",
    "\n",
    "    model_inputs = tokenizer(inputs, max_length=max_seq_length, padding=padding, truncation=True)\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_answer_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\" and data_args.ignore_pad_token_for_loss:\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23c623ec-da6e-4580-88a8-fe7d716e586b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask', 'labels']),\n",
       " torch.Size([2, 30]),\n",
       " tensor([[  7680,    267,   5126,    339,    287,   8646,   9416,    304,  25828,\n",
       "             291,  19730,    267,    259,  24633, 108364,   1881,  47815,  44628,\n",
       "          208385, 172171,  11984,  33555, 111284,    274, 220992,    296,    364,\n",
       "           21058,    271,      1],\n",
       "         [  7680,    267,  26104,    339,    287,  16780,    723,    304,  35878,\n",
       "             291,  19730,    267,    259,  24633, 108364,   1881,  47815,  44628,\n",
       "          208385, 172171,  11984,  33555, 111284,    274, 220992,    296,    364,\n",
       "           21058,    271,      1]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ins = preprocess_function(examples=examples,\n",
    "                    question_column='question',\n",
    "                    context_column='context',\n",
    "                    answer_column='answers')\n",
    "\n",
    "model_ins.keys(), torch.LongTensor(model_ins['input_ids']).shape, torch.LongTensor(model_ins['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b50ada4b-2512-402d-86ec-13186af62171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing:\n",
    "def post_processing_function(\n",
    "    examples: datasets.Dataset, features: datasets.Dataset, outputs: EvalLoopOutput, stage=\"eval\"\n",
    "):\n",
    "    # Decode the predicted tokens.\n",
    "    preds = outputs.predictions\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Build a map example to its corresponding features.\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    feature_per_example = {example_id_to_index[feature[\"example_id\"]]: i for i, feature in enumerate(features)}\n",
    "    predictions = {}\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in enumerate(examples):\n",
    "        # This is the index of the feature associated to the current example.\n",
    "        feature_index = feature_per_example[example_index]\n",
    "        predictions[example[\"id\"]] = decoded_preds[feature_index]\n",
    "\n",
    "    # Format the result to the format the metric expects.\n",
    "    if data_args.version_2_with_negative:\n",
    "        formatted_predictions = [\n",
    "            {\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in predictions.items()\n",
    "        ]\n",
    "    else:\n",
    "        formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in predictions.items()]\n",
    "\n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": ex[answer_column]} for ex in examples]\n",
    "    return EvalPrediction(predictions=formatted_predictions, label_ids=references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75372de3-ffa5-489a-86bc-cfde202808ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "  data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=label_pad_token_id,\n",
    "        pad_to_multiple_of=8 if training_args.fp16 else None,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369bf01-2e33-48d6-823f-64d5572f1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "\n",
    "        \n",
    "input_ids = tokenizer(\"translate English to German: The house is wonderful.\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "Das Haus ist wunderbar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
